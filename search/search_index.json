{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"BlackBIRDS documentation","text":"<p>BlackBIRDS is a Python package consisting of generically applicable, black-box inference methods for differentiable simulation models. It facilitates both (a) the differentiable implementation of simulation models by providing a common object-oriented framework for their implementation in PyTorch, and (b) the use of a variety of gradient-assisted inference procedures for these simulation models, allowing researchers to easily exploit the differentiable nature of their simulator in parameter estimation tasks. The package consists of both Bayesian and non-Bayesian inference methods, and relies on well-supported software libraries (e.g. normflows, Stimper et al. (2023)) to provide this broad functionality.</p>"},{"location":"#installation","title":"Installation","text":"<p>The easiest way to install the package is to obtain it from the PyPI repository</p> <pre><code>pip install blackbirds\n</code></pre> <p>Alternatively, you can obtain the latest version directly from git, </p> <pre><code>pip install git+https://github.com/arnauqb/blackbirds\n</code></pre>"},{"location":"api/jacfwd/","title":"JACFWD","text":"<p>Wrapper around torch._functorch.jacfwd that accepts chunk size. See the original torch documentation for more details on the arguments.</p> <p>Arguments:</p> <ul> <li><code>func</code>: A Python function that takes one or more arguments, one of which     must be a Tensor, and returns one or more Tensors</li> <li><code>argnums</code>: An integer or a tuple of integers specifying which positional     argument(s) to differentiate with respect to.</li> <li><code>has_aux</code>: If <code>True</code>, <code>func</code> is assumed to return a pair where the first     element is considered the output of the original function to be     differentiated and the second element is auxiliary data.</li> <li><code>randomness</code>: A string specifying how to handle randomness in <code>func</code>.     Valid values are \u201cdifferent\u201d, \u201csame\u201d, \u201cerror\u201d.</li> <li><code>chunk_size</code>: An integer specifying the chunk size for vmap.</li> </ul> Source code in <code>blackbirds/jacfwd.py</code> <pre><code>def jacfwd(\n    func: Callable,\n    argnums: argnums_t = 0,\n    has_aux: bool = False,\n    *,\n    randomness: str = \"error\",\n    chunk_size=None\n):\n\"\"\"\n    Wrapper around torch._functorch.jacfwd that accepts chunk size.\n    See the original torch documentation for more details on the arguments.\n\n    **Arguments:**\n\n    - `func`: A Python function that takes one or more arguments, one of which\n        must be a Tensor, and returns one or more Tensors\n    - `argnums`: An integer or a tuple of integers specifying which positional\n        argument(s) to differentiate with respect to.\n    - `has_aux`: If `True`, `func` is assumed to return a pair where the first\n        element is considered the output of the original function to be\n        differentiated and the second element is auxiliary data.\n    - `randomness`: A string specifying how to handle randomness in `func`.\n        Valid values are \u201cdifferent\u201d, \u201csame\u201d, \u201cerror\u201d.\n    - `chunk_size`: An integer specifying the chunk size for vmap.\n    \"\"\"\n    @wraps(func)\n    def wrapper_fn(*args):\n        primals = args if argnums is None else _slice_argnums(args, argnums)\n        flat_primals, primals_spec = tree_flatten(primals)\n        flat_primals_numels = tuple(p.numel() for p in flat_primals)\n        flat_basis = _construct_standard_basis_for(flat_primals, flat_primals_numels)\n        basis = tree_unflatten(flat_basis, primals_spec)\n\n        def push_jvp(basis):\n            output = _jvp_with_argnums(\n                func, args, basis, argnums=argnums, has_aux=has_aux\n            )\n            # output[0] is the output of `func(*args)`\n            if has_aux:\n                _, jvp_out, aux = output\n                return jvp_out, aux\n            _, jvp_out = output\n            return jvp_out\n\n        results = vmap(push_jvp, randomness=randomness, chunk_size=chunk_size)(basis)\n        if has_aux:\n            results, aux = results\n            # aux is in the standard basis format, e.g. NxN matrix\n            # We need to fetch the first element as original `func` output\n            flat_aux, aux_spec = tree_flatten(aux)\n            flat_aux = [value[0] for value in flat_aux]\n            aux = tree_unflatten(flat_aux, aux_spec)\n\n        jac_outs, spec = tree_flatten(results)\n        # Most probably below output check can never raise an error\n        # as jvp should test the output before\n        # assert_non_empty_output(jac_outs, 'jacfwd(f, ...)(*args)')\n\n        jac_outs_ins = tuple(\n            tuple(\n                safe_unflatten(jac_out_in, -1, primal.shape)\n                for primal, jac_out_in in zip(\n                    flat_primals,\n                    jac_out.movedim(0, -1).split(flat_primals_numels, dim=-1),\n                )\n            )\n            for jac_out in jac_outs\n        )\n        jac_outs_ins = tuple(\n            tree_unflatten(jac_ins, primals_spec) for jac_ins in jac_outs_ins\n        )\n\n        if isinstance(argnums, int):\n            jac_outs_ins = tuple(jac_ins[0] for jac_ins in jac_outs_ins)\n        if has_aux:\n            return tree_unflatten(jac_outs_ins, spec), aux\n        return tree_unflatten(jac_outs_ins, spec)\n\n    return wrapper_fn\n</code></pre>"},{"location":"api/losses/","title":"Example losses","text":""},{"location":"api/losses/#blackbirds.losses.SingleOutput_SimulateAndMMD","title":"<code>SingleOutput_SimulateAndMMD</code>","text":"<p>Example implementation of a loss that simulates from the model and computes the MMD between the model output and observed data y. (This treats the entries in y and in the simulator output as exchangeable.)</p> <p>Arguments:</p> <ul> <li><code>y</code>: torch.Tensor containing a single univariate time series.</li> <li><code>model</code>: An instance of a Model.</li> <li><code>gradient_horizon</code>: An integer or None. Sets horizon over which gradients are retained. If None, infinite horizon used.</li> </ul> Source code in <code>blackbirds/losses.py</code> <pre><code>class SingleOutput_SimulateAndMMD:\n\"\"\"\n    Example implementation of a loss that simulates from the model and computes the MMD\n    between the model output and observed data y. (This treats the entries in y and in\n    the simulator output as exchangeable.)\n\n    **Arguments:**\n\n    - `y`: torch.Tensor containing a single univariate time series.\n    - `model`: An instance of a Model.\n    - `gradient_horizon`: An integer or None. Sets horizon over which gradients are retained. If None, infinite horizon used.\n    \"\"\"\n    def __init__(\n        self, y: torch.Tensor, model: Model, gradient_horizon: Union[int, None] = None\n    ):\n        self.mmd_loss = UnivariateMMDLoss(y)\n        self.model = model\n        self.gradient_horizon = gradient_horizon\n\n    def __call__(self, theta: torch.Tensor, y: torch.Tensor):\n        x = simulate_and_observe_model(self.model, theta, self.gradient_horizon)[0]\n        return self.mmd_loss(x)\n</code></pre>"},{"location":"api/losses/#blackbirds.losses.SingleOutput_SimulateAndMSELoss","title":"<code>SingleOutput_SimulateAndMSELoss</code>","text":"<p>Computes MSE between observed data y and simulated data at theta (to be passed during call).</p> <p>Arguments:</p> <ul> <li><code>model</code>: An instance of a Model. The model that you'd like to \"fit\".</li> <li><code>gradient_horizon</code>: Specifies the gradient horizon to use. None implies infinite horizon.</li> </ul> Source code in <code>blackbirds/losses.py</code> <pre><code>class SingleOutput_SimulateAndMSELoss:\n\n\"\"\"\n    Computes MSE between observed data y and simulated data at theta (to be passed during __call__).\n\n    **Arguments:**\n\n    - `model`: An instance of a Model. The model that you'd like to \"fit\".\n    - `gradient_horizon`: Specifies the gradient horizon to use. None implies infinite horizon.\n    \"\"\"\n\n    def __init__(self, model: Model, gradient_horizon: Union[int, None] = None):\n        self.loss = torch.nn.MSELoss()\n        self.model = model\n        self.gradient_horizon = gradient_horizon\n\n    def __call__(\n        self,\n        theta: torch.Tensor,\n        y: torch.Tensor,\n    ):\n        x = simulate_and_observe_model(self.model, theta, self.gradient_horizon)[0]\n        return self.loss(x, y)\n</code></pre>"},{"location":"api/losses/#blackbirds.losses.UnivariateMMDLoss","title":"<code>UnivariateMMDLoss</code>","text":"Source code in <code>blackbirds/losses.py</code> <pre><code>class UnivariateMMDLoss:\n    def __init__(self, y: torch.Tensor):\n\"\"\"\n        Computes MMD between data y and simulated output x (to be passed during call).\n\n        **Arguments:**\n\n        - `y`: torch.Tensor containing a single univariate time series.\n        \"\"\"\n        assert isinstance(y, torch.Tensor), \"y is assumed to be a torch.Tensor here\"\n        try:\n            assert (\n                len(y.shape) == 1\n            ), \"This class assumes y is a single univariate time series\"\n        except AssertionError:\n            assert (\n                len(y.shape) == 2\n            ), \"If not a 1D Tensor, y must be at most 2D of shape (1, T)\"\n            assert (\n                y.shape[1] == 1\n            ), \"This class assumes y is a single univariate time series. This appears to be a batch of data.\"\n            y = y.reshape(-1)\n        self.device = y.device\n        self.y = y\n        self.y_matrix = self.y.reshape(1, -1, 1)\n        yy = torch.cdist(self.y_matrix, self.y_matrix)\n        yy_sqrd = torch.pow(yy, 2)\n        self.y_sigma = torch.median(yy_sqrd)\n        ny = self.y.shape[0]\n        self.kyy = (\n            torch.exp(-yy_sqrd / self.y_sigma) - torch.eye(ny, device=self.device)\n        ).sum() / (ny * (ny - 1))\n\n    def __call__(\n        self,\n        x: torch.Tensor,\n    ):\n        assert isinstance(x, torch.Tensor), \"x is assumed to be a torch.Tensor here\"\n        try:\n            assert (\n                len(x.shape) == 1\n            ), \"This class assumes x is a single univariate time series\"\n        except AssertionError:\n            assert (\n                len(x.shape) == 2\n            ), \"If not a 1D Tensor, x must be at most 2D of shape (1, T)\"\n            assert (\n                x.shape[1] == 1\n            ), \"This class assumes x is a single univariate time series. This appears to be a batch of data.\"\n            x = x.reshape(-1)\n\n        nx = x.shape[0]\n        x_matrix = x.reshape(1, -1, 1)\n        kxx = torch.exp(-torch.pow(torch.cdist(x_matrix, x_matrix), 2) / self.y_sigma)\n        kxx = (kxx - torch.eye(nx, device=self.device)).sum() / (nx * (nx - 1))\n        kxy = torch.exp(\n            -torch.pow(torch.cdist(x_matrix, self.y_matrix), 2) / self.y_sigma\n        )\n        kxy = kxy.mean()\n        return kxx + self.kyy - 2 * kxy\n</code></pre>"},{"location":"api/losses/#blackbirds.losses.UnivariateMMDLoss.__init__","title":"<code>__init__(y)</code>","text":"<p>Computes MMD between data y and simulated output x (to be passed during call).</p> <p>Arguments:</p> <ul> <li><code>y</code>: torch.Tensor containing a single univariate time series.</li> </ul> Source code in <code>blackbirds/losses.py</code> <pre><code>def __init__(self, y: torch.Tensor):\n\"\"\"\n    Computes MMD between data y and simulated output x (to be passed during call).\n\n    **Arguments:**\n\n    - `y`: torch.Tensor containing a single univariate time series.\n    \"\"\"\n    assert isinstance(y, torch.Tensor), \"y is assumed to be a torch.Tensor here\"\n    try:\n        assert (\n            len(y.shape) == 1\n        ), \"This class assumes y is a single univariate time series\"\n    except AssertionError:\n        assert (\n            len(y.shape) == 2\n        ), \"If not a 1D Tensor, y must be at most 2D of shape (1, T)\"\n        assert (\n            y.shape[1] == 1\n        ), \"This class assumes y is a single univariate time series. This appears to be a batch of data.\"\n        y = y.reshape(-1)\n    self.device = y.device\n    self.y = y\n    self.y_matrix = self.y.reshape(1, -1, 1)\n    yy = torch.cdist(self.y_matrix, self.y_matrix)\n    yy_sqrd = torch.pow(yy, 2)\n    self.y_sigma = torch.median(yy_sqrd)\n    ny = self.y.shape[0]\n    self.kyy = (\n        torch.exp(-yy_sqrd / self.y_sigma) - torch.eye(ny, device=self.device)\n    ).sum() / (ny * (ny - 1))\n</code></pre>"},{"location":"api/mpi_setup/","title":"MPI Setup","text":""},{"location":"api/posterior_estimators/","title":"Example posterior estimators","text":"<p>             Bases: <code>Module</code></p> <p>A multivariate Gaussian distribution with trainable mean and covariance  matrix.</p> <p>Arguments:</p> <ul> <li><code>mu</code>: list of floats, the initial mean of the distribution.</li> <li><code>sigma</code>: float, the initial standard deviation of the distribution.     The covariance matrix is initialized as a diagonal matrix with this     value on the diagonal.</li> <li><code>device</code>: str, the device to use for the distribution.</li> </ul> Source code in <code>blackbirds/posterior_estimators.py</code> <pre><code>class TrainableGaussian(torch.nn.Module):\n\"\"\"\n    A multivariate Gaussian distribution with trainable mean and covariance \n    matrix.\n\n    **Arguments:**\n\n    - `mu`: list of floats, the initial mean of the distribution.\n    - `sigma`: float, the initial standard deviation of the distribution.\n        The covariance matrix is initialized as a diagonal matrix with this\n        value on the diagonal.\n    - `device`: str, the device to use for the distribution.\n    \"\"\"\n    def __init__(self, mu=[0.0], sigma=1.0, device=\"cpu\"):\n        super().__init__()\n        self.mu = torch.nn.Parameter(torch.tensor(mu, device=device))\n        self.sigma = sigma * torch.eye(len(mu), device=device)\n        self.sigma = torch.nn.Parameter(self.sigma)\n\n    def clamp_sigma(self):\n        sigma = self.sigma.clone()\n        mask = torch.eye(len(self.mu), device=self.sigma.device).bool()\n        sigma[mask] = torch.clamp(self.sigma[mask], min=1e-3)\n        return sigma\n\n    def log_prob(self, x):\n        sigma = self.clamp_sigma()\n        return torch.distributions.MultivariateNormal(self.mu, sigma).log_prob(x)\n\n    def sample(self, n):\n        sigma = self.clamp_sigma()\n        dist = torch.distributions.MultivariateNormal(self.mu, sigma)\n        sample = dist.rsample((n,))\n        return sample, self.log_prob(sample.detach())\n\n    def __call__(self, x=None):\n        return self\n</code></pre>"},{"location":"api/simulate/","title":"Simulate","text":""},{"location":"api/simulate/#blackbirds.simulate.compute_loss","title":"<code>compute_loss(loss_fn, observed_outputs, simulated_outputs)</code>","text":"<p>Compute the loss between observed and simulated outputs.</p> <p>Arguments:</p> <ul> <li>loss_fn : loss function</li> <li>observed_outputs : list of data tensors to calibrate to</li> <li>simulated_outputs: list of simulated outputs</li> </ul> <p>Example</p> <pre><code>loss_fn = torch.nn.MSELoss()\nobserved_outputs = [torch.tensor([1, 2, 3]), torch.tensor([4, 5, 6])]\nsimulated_outputs = [torch.tensor([1, 2, 3]), torch.tensor([4, 5, 6])]\ncompute_loss(loss_fn, observed_outputs, simulated_outputs) # tensor(0.)\n</code></pre> Source code in <code>blackbirds/simulate.py</code> <pre><code>def compute_loss(\n    loss_fn: Callable,\n    observed_outputs: list[torch.Tensor],\n    simulated_outputs: list[torch.Tensor],\n) -&gt; torch.Tensor:\n\"\"\"Compute the loss between observed and simulated outputs.\n\n    **Arguments:**\n\n    - loss_fn : loss function\n    - observed_outputs : list of data tensors to calibrate to\n    - simulated_outputs: list of simulated outputs\n\n    !!! example\n        ```python\n        loss_fn = torch.nn.MSELoss()\n        observed_outputs = [torch.tensor([1, 2, 3]), torch.tensor([4, 5, 6])]\n        simulated_outputs = [torch.tensor([1, 2, 3]), torch.tensor([4, 5, 6])]\n        compute_loss(loss_fn, observed_outputs, simulated_outputs) # tensor(0.)\n        ```\n    \"\"\"\n    try:\n        assert len(observed_outputs) == len(simulated_outputs)\n    except AssertionError:\n        raise ValueError(\"Number of observed and simulated outputs must be the same.\")\n    loss = 0\n    is_nan = True\n    for observed_output, simulated_output in zip(observed_outputs, simulated_outputs):\n        try:\n            assert observed_output.shape == simulated_output.shape\n        except AssertionError:\n            raise ValueError(\"Observed and simulated outputs must have the same shape\")\n        if torch.isnan(simulated_output).any():\n            warnings.warn(\"Simulation produced nan -- ignoring\")\n            continue\n        loss += loss_fn(simulated_output, observed_output)\n        is_nan = False\n    if is_nan:\n        return torch.tensor(torch.nan), torch.tensor(torch.nan)\n    return loss, loss  # need to return it twice for jac calculation\n</code></pre>"},{"location":"api/simulate/#blackbirds.simulate.simulate_and_observe_model","title":"<code>simulate_and_observe_model(model, params, gradient_horizon=None)</code>","text":"<p>Runs the simulator for the given parameters and calls the model's observe method. To avoid gradient instabilities, the <code>gradient_horizon</code> argument limits the number of past time-steps that are taken into account for the gradient's calculation. That is, if <code>gradient_horizon</code> is 10, then only the last 10 time-steps are used to calculate the gradient.</p> <p>Arguments:</p> <ul> <li><code>model</code>: A torch.nn.Module implemnting the <code>initialize</code>, <code>forward</code> and <code>observe</code> methods.</li> <li><code>params</code>: The parameters taken by the model's <code>forward</code> method.</li> <li><code>n_timesteps</code>: Number of timesteps to simulate.</li> <li><code>gradient_horizon</code>: Gradient window, if None then all time-steps are used to calculate the gradient.</li> </ul> Source code in <code>blackbirds/simulate.py</code> <pre><code>def simulate_and_observe_model(\n    model: torch.nn.Module,\n    params: torch.Tensor,\n    gradient_horizon: Union[int,  None] = None,\n):\n\"\"\"Runs the simulator for the given parameters and calls the model's observe method.\n    To avoid gradient instabilities, the `gradient_horizon` argument limits the number of past time-steps\n    that are taken into account for the gradient's calculation. That is, if `gradient_horizon` is 10, then\n    only the last 10 time-steps are used to calculate the gradient.\n\n    **Arguments:**\n\n    - `model`: A torch.nn.Module implemnting the `initialize`, `forward` and `observe` methods.\n    - `params`: The parameters taken by the model's `forward` method.\n    - `n_timesteps`: Number of timesteps to simulate.\n    - `gradient_horizon`: Gradient window, if None then all time-steps are used to calculate the gradient.\n    \"\"\"\n    if gradient_horizon is None:\n        gradient_horizon = model.n_timesteps\n    # Initialize the model\n    time_series = model.initialize(params)\n    observed_outputs = model.observe(time_series)\n    for t in range(model.n_timesteps):\n        time_series = model.trim_time_series(\n            time_series\n        )  # gets past time-steps needed to compute the next one.\n        # only consider the past gradient_horizon time-steps to calculate the gradient\n        if t &gt; gradient_horizon:\n            time_series = model.detach_gradient_horizon(time_series, gradient_horizon)\n        x = model(params, time_series)\n        observed_outputs = [\n            torch.cat((observed_output, output))\n            for observed_output, output in zip(observed_outputs, model.observe(x))\n        ]\n        if time_series is not None:\n            time_series = torch.cat((time_series, x))\n    return observed_outputs\n</code></pre>"},{"location":"api/utils/","title":"Utils","text":""},{"location":"api/utils/#blackbirds.utils.soft_maximum","title":"<code>soft_maximum(a, b, k)</code>","text":"<p>Soft differentiable maximum function.</p> <p>Arguments:</p> <ul> <li><code>a</code>: First input tensor.</li> <li><code>b</code>: Second input tensor.</li> <li><code>k</code>: Hardness.</li> </ul> Source code in <code>blackbirds/utils.py</code> <pre><code>def soft_maximum(a: torch.Tensor, b: torch.Tensor, k: float):\n\"\"\"\n    Soft differentiable maximum function.\n\n    **Arguments:**\n\n    - `a`: First input tensor.\n    - `b`: Second input tensor.\n    - `k`: Hardness.\n    \"\"\"\n    return torch.log(torch.exp(k * a) + torch.exp(k * b)) / k\n</code></pre>"},{"location":"api/utils/#blackbirds.utils.soft_minimum","title":"<code>soft_minimum(a, b, k)</code>","text":"<p>Soft differentiable minimum function.</p> <p>Arguments:</p> <ul> <li><code>a</code>: First input tensor.</li> <li><code>b</code>: Second input tensor.</li> <li><code>k</code>: Hardness.</li> </ul> Source code in <code>blackbirds/utils.py</code> <pre><code>def soft_minimum(a: torch.Tensor, b: torch.Tensor, k: float):\n\"\"\"\n    Soft differentiable minimum function.\n\n    **Arguments:**\n\n    - `a`: First input tensor.\n    - `b`: Second input tensor.\n    - `k`: Hardness.\n    \"\"\"\n    return -soft_maximum(-a, -b, k)\n</code></pre>"},{"location":"api/infer/mcmc/","title":"MCMC","text":"<p>             Bases: <code>MCMCKernel</code></p> <p>Class that generates a step in the chain of a Metropolis-Adjusted Langevin Algorithm run.</p> <p>Arguments</p> <ul> <li><code>prior</code>: The prior distribution. Must be differentiable in its argument.</li> <li><code>w</code>: The weight hyperparameter in generalised posterior.</li> <li><code>gradient_clipping_norm</code>: The norm to which the gradients are clipped.</li> <li><code>loss</code>: The loss function used in the exponent of the generalised likelihood term. Maps from data and chain state to loss.</li> <li><code>diff_mode</code>: The differentiation mode to use. Can be either 'reverse' or 'forward'.</li> <li><code>jacobian_chunk_size</code>: The number of rows computed at a time for the model Jacobian. Set to None to compute the full Jacobian at once.</li> <li><code>gradient_horizon</code>: The number of timesteps to use for the gradient horizon. Set 0 to use the full trajectory.</li> <li><code>device</code>: The device to use for training.</li> <li><code>discretisation_method</code>: How to discretise the overdamped Langevin diffusion. Default 'e-m' for Euler-Maruyama</li> </ul> Source code in <code>blackbirds/infer/mcmc.py</code> <pre><code>class MALA(MCMCKernel):\n\"\"\"\n    Class that generates a step in the chain of a Metropolis-Adjusted Langevin Algorithm run.\n\n    **Arguments**\n\n    - `prior`: The prior distribution. Must be differentiable in its argument.\n    - `w`: The weight hyperparameter in generalised posterior.\n    - `gradient_clipping_norm`: The norm to which the gradients are clipped.\n    - `loss`: The loss function used in the exponent of the generalised likelihood term. Maps from data and chain state to loss.\n    - `diff_mode`: The differentiation mode to use. Can be either 'reverse' or 'forward'.\n    - `jacobian_chunk_size`: The number of rows computed at a time for the model Jacobian. Set to None to compute the full Jacobian at once.\n    - `gradient_horizon`: The number of timesteps to use for the gradient horizon. Set 0 to use the full trajectory.\n    - `device`: The device to use for training.\n    - `discretisation_method`: How to discretise the overdamped Langevin diffusion. Default 'e-m' for Euler-Maruyama\n    \"\"\"\n\n    def __init__(\n        self,\n        *args,\n        discretisation_method: str = \"e-m\",\n        **kwargs\n    ):\n        super().__init__(*args, **kwargs)\n        self.discretisation_method = discretisation_method\n        self._previous_log_density = None\n        self._previous_grad_theta_of_log_density = None\n        self._proposal = None\n\n    def _compute_log_density_and_grad(self, state, data):\n        _state = state.clone().detach()\n        _state.requires_grad = True\n        ell = self.loss(_state, data)\n        log_prior_pdf = self.prior.log_prob(_state)\n        log_density = -ell + log_prior_pdf * self.w\n        log_density.backward()\n        torch.nn.utils.clip_grad_norm_([_state], self.gradient_clipping_norm)\n        return log_density.detach(), _state.grad\n\n    def initialise_chain(self, state, data):\n        log_density, grad_theta_of_log_density = self._compute_log_density_and_grad(\n            state, data\n        )\n        self._previous_log_density = log_density\n        self._previous_grad_theta_of_log_density = grad_theta_of_log_density\n        self._proposal = None\n\n    def step(\n        self,\n        current_state,\n        data,\n        scale: float = 1.0,\n        covariance: Union[torch.Tensor, None] = None,\n    ):\n\"\"\"\n        Returns a (torch.Tensor, bool) pair corresponding to (the current state of the chain, whether\n        the current state resulted from an accept or reject decision in the Metropolis step).\n        \"\"\"\n\n        if covariance is None:\n            covariance = torch.eye(self._dim)\n        sC = scale * covariance\n        if self._previous_log_density is None:\n            # This would happen if the user hasn't initialised the chain themselves\n            self.initialise_chain(current_state, data)\n        if self.discretisation_method == \"e-m\":\n            if self._proposal is None:\n                # This would happen if the user hasn't initialised the chain themselves\n                gradient_term = torch.matmul(\n                    sC, self._previous_grad_theta_of_log_density\n                )\n                mean = current_state + gradient_term\n                logger.debug(\"Total mean =\", mean)\n                logger.debug(\"Gradient_term =\", gradient_term)\n                proposal = torch.distributions.multivariate_normal.MultivariateNormal(\n                    mean, covariance_matrix=2 * sC\n                )\n                self._proposal = proposal\n            new_state = self._proposal.sample()\n        else:\n            raise NotImplementedError(\"Discretisation method not yet implemented\")\n\n        (\n            new_log_density,\n            grad_theta_of_new_log_density,\n        ) = self._compute_log_density_and_grad(new_state, data)\n\n        # Metropolis accept/reject step\n        log_alpha = torch.log(torch.rand((1,))[0])\n        # Compute reverse proposal logpdf\n        if self.discretisation_method == \"e-m\":\n            try:\n                rev_proposal = (\n                    torch.distributions.multivariate_normal.MultivariateNormal(\n                        new_state + torch.matmul(sC, grad_theta_of_new_log_density),\n                        covariance_matrix=2 * sC,\n                    )\n                )\n            except ValueError as e:\n                logger.debug(new_state, grad_theta_of_new_log_density)\n                raise e\n        else:\n            raise NotImplementedError(\"Discretisation method not yet implemented\")\n        log_accept_prob = (\n            new_log_density\n            + rev_proposal.log_prob(current_state)\n            - self._previous_log_density\n            - self._proposal.log_prob(new_state)\n        )\n        logger.debug(\"Current, new:\", current_state, new_state)\n        logger.debug(\n            \"Lalpha\",\n            log_accept_prob.item(),\n            \" = \",\n            new_log_density.item(),\n            \"+\",\n            rev_proposal.log_prob(current_state).item(),\n            \"-\",\n            self._previous_log_density.item(),\n            \"-\",\n            self._proposal.log_prob(new_state).item(),\n        )\n        logger.debug(\"\")\n        accept = log_alpha &lt; log_accept_prob\n        if accept:\n            self._previous_log_density = new_log_density\n            self._previous_grad_theta_of_log_density = grad_theta_of_new_log_density\n            self._proposal = rev_proposal\n            return new_state, True\n        return current_state, False\n</code></pre> <p>Class that runs an MCMC chain.</p> <p>Arguments</p> <ul> <li><code>kernel</code>: An object with a .step() method that is used to generate the next sample in the chain.</li> <li><code>num_samples</code>: An integer specifying the number of samples to generate in the MCMC chain.</li> <li><code>progress_bar</code>: Whether to display a progress bar during training.</li> <li><code>progress_info</code>: Whether to display loss data during training.</li> </ul> Source code in <code>blackbirds/infer/mcmc.py</code> <pre><code>class MCMC:\n\"\"\"\n    Class that runs an MCMC chain.\n\n    **Arguments**\n\n    - `kernel`: An object with a .step() method that is used to generate the next sample in the chain.\n    - `num_samples`: An integer specifying the number of samples to generate in the MCMC chain.\n    - `progress_bar`: Whether to display a progress bar during training.\n    - `progress_info`: Whether to display loss data during training.\n    \"\"\"\n\n    def __init__(\n        self,\n        kernel: MCMCKernel,\n        num_samples: int = 100_000,\n        progress_bar: bool = True,\n        progress_info: bool = True,\n    ):\n        self.kernel = kernel\n        self.num_samples = num_samples\n        self.progress_bar = progress_bar\n        self.progress_info = progress_info\n        # I suppose just in case something stops the program and you want to save the samples?\n        self._samples = []\n\n    def reset(self):\n        self._samples = []\n\n    def run(\n        self,\n        initial_state: torch.Tensor, \n        data: torch.Tensor, \n        *args, \n        seed: int = 0,\n        T: int = 1, \n        **kwargs\n    ):\n\n\"\"\"\n        Runs the MCMC chain.\n\n        **Arguments**\n\n        - `initial_state`: Starting location of the MCMC chain.\n        - `data`: A torch.Tensor containing the data against which the simulator is compared.\n        - `seed`: An integer specifying the initial random state of the RNG.\n        - `T`: An integer specifying the number of steps between updates of the progress info (if shown).\n\n        Additional arguments and keyword arguments can be passed, which will be passed to the kernel \n        .step() method.\n        \"\"\"\n\n        assert isinstance(initial_state, torch.Tensor), \"Initial state of the MCMC chain must be a torch.Tensor\"\n        assert isinstance(data, torch.Tensor), \"The data must be passed as a torch.Tensor\"\n\n        if seed is not None:\n            torch.manual_seed(seed)\n        self.reset()\n\n        if self.progress_bar:\n            iterator = trange(self.num_samples)\n        else:\n            iterator = range(self.num_samples)\n\n        self._samples.append(initial_state)\n        state = initial_state\n        if self.progress_info:\n            total_accepted = 0\n        for t in iterator:\n            state, accept_step = self.kernel.step(state, data, *args, **kwargs)\n            self._samples.append(state)\n            if self.progress_info:\n                if accept_step:\n                    total_accepted += 1\n                if t % T == 0:\n                    iterator.set_postfix(\n                        {\"Acceptance rate\": float(total_accepted) / (t + 1.0)}\n                    )\n        return self._samples\n</code></pre>"},{"location":"api/infer/mcmc/#blackbirds.infer.mcmc.MALA.step","title":"<code>step(current_state, data, scale=1.0, covariance=None)</code>","text":"<p>Returns a (torch.Tensor, bool) pair corresponding to (the current state of the chain, whether the current state resulted from an accept or reject decision in the Metropolis step).</p> Source code in <code>blackbirds/infer/mcmc.py</code> <pre><code>def step(\n    self,\n    current_state,\n    data,\n    scale: float = 1.0,\n    covariance: Union[torch.Tensor, None] = None,\n):\n\"\"\"\n    Returns a (torch.Tensor, bool) pair corresponding to (the current state of the chain, whether\n    the current state resulted from an accept or reject decision in the Metropolis step).\n    \"\"\"\n\n    if covariance is None:\n        covariance = torch.eye(self._dim)\n    sC = scale * covariance\n    if self._previous_log_density is None:\n        # This would happen if the user hasn't initialised the chain themselves\n        self.initialise_chain(current_state, data)\n    if self.discretisation_method == \"e-m\":\n        if self._proposal is None:\n            # This would happen if the user hasn't initialised the chain themselves\n            gradient_term = torch.matmul(\n                sC, self._previous_grad_theta_of_log_density\n            )\n            mean = current_state + gradient_term\n            logger.debug(\"Total mean =\", mean)\n            logger.debug(\"Gradient_term =\", gradient_term)\n            proposal = torch.distributions.multivariate_normal.MultivariateNormal(\n                mean, covariance_matrix=2 * sC\n            )\n            self._proposal = proposal\n        new_state = self._proposal.sample()\n    else:\n        raise NotImplementedError(\"Discretisation method not yet implemented\")\n\n    (\n        new_log_density,\n        grad_theta_of_new_log_density,\n    ) = self._compute_log_density_and_grad(new_state, data)\n\n    # Metropolis accept/reject step\n    log_alpha = torch.log(torch.rand((1,))[0])\n    # Compute reverse proposal logpdf\n    if self.discretisation_method == \"e-m\":\n        try:\n            rev_proposal = (\n                torch.distributions.multivariate_normal.MultivariateNormal(\n                    new_state + torch.matmul(sC, grad_theta_of_new_log_density),\n                    covariance_matrix=2 * sC,\n                )\n            )\n        except ValueError as e:\n            logger.debug(new_state, grad_theta_of_new_log_density)\n            raise e\n    else:\n        raise NotImplementedError(\"Discretisation method not yet implemented\")\n    log_accept_prob = (\n        new_log_density\n        + rev_proposal.log_prob(current_state)\n        - self._previous_log_density\n        - self._proposal.log_prob(new_state)\n    )\n    logger.debug(\"Current, new:\", current_state, new_state)\n    logger.debug(\n        \"Lalpha\",\n        log_accept_prob.item(),\n        \" = \",\n        new_log_density.item(),\n        \"+\",\n        rev_proposal.log_prob(current_state).item(),\n        \"-\",\n        self._previous_log_density.item(),\n        \"-\",\n        self._proposal.log_prob(new_state).item(),\n    )\n    logger.debug(\"\")\n    accept = log_alpha &lt; log_accept_prob\n    if accept:\n        self._previous_log_density = new_log_density\n        self._previous_grad_theta_of_log_density = grad_theta_of_new_log_density\n        self._proposal = rev_proposal\n        return new_state, True\n    return current_state, False\n</code></pre>"},{"location":"api/infer/mcmc/#blackbirds.infer.mcmc.MCMC.run","title":"<code>run(initial_state, data, *args, seed=0, T=1, **kwargs)</code>","text":"<p>Runs the MCMC chain.</p> <p>Arguments</p> <ul> <li><code>initial_state</code>: Starting location of the MCMC chain.</li> <li><code>data</code>: A torch.Tensor containing the data against which the simulator is compared.</li> <li><code>seed</code>: An integer specifying the initial random state of the RNG.</li> <li><code>T</code>: An integer specifying the number of steps between updates of the progress info (if shown).</li> </ul> <p>Additional arguments and keyword arguments can be passed, which will be passed to the kernel  .step() method.</p> Source code in <code>blackbirds/infer/mcmc.py</code> <pre><code>def run(\n    self,\n    initial_state: torch.Tensor, \n    data: torch.Tensor, \n    *args, \n    seed: int = 0,\n    T: int = 1, \n    **kwargs\n):\n\n\"\"\"\n    Runs the MCMC chain.\n\n    **Arguments**\n\n    - `initial_state`: Starting location of the MCMC chain.\n    - `data`: A torch.Tensor containing the data against which the simulator is compared.\n    - `seed`: An integer specifying the initial random state of the RNG.\n    - `T`: An integer specifying the number of steps between updates of the progress info (if shown).\n\n    Additional arguments and keyword arguments can be passed, which will be passed to the kernel \n    .step() method.\n    \"\"\"\n\n    assert isinstance(initial_state, torch.Tensor), \"Initial state of the MCMC chain must be a torch.Tensor\"\n    assert isinstance(data, torch.Tensor), \"The data must be passed as a torch.Tensor\"\n\n    if seed is not None:\n        torch.manual_seed(seed)\n    self.reset()\n\n    if self.progress_bar:\n        iterator = trange(self.num_samples)\n    else:\n        iterator = range(self.num_samples)\n\n    self._samples.append(initial_state)\n    state = initial_state\n    if self.progress_info:\n        total_accepted = 0\n    for t in iterator:\n        state, accept_step = self.kernel.step(state, data, *args, **kwargs)\n        self._samples.append(state)\n        if self.progress_info:\n            if accept_step:\n                total_accepted += 1\n            if t % T == 0:\n                iterator.set_postfix(\n                    {\"Acceptance rate\": float(total_accepted) / (t + 1.0)}\n                )\n    return self._samples\n</code></pre>"},{"location":"api/infer/smd/","title":"Simulated Minimum Distance","text":"Source code in <code>blackbirds/infer/smd.py</code> <pre><code>class SMD:\n    def __init__(self, loss, optimizer, gradient_horizon=None, progress_bar=False):\n\"\"\"\n        Simulated Minimum Distance. Finds the point in parameter space that\n        minimizes the distance between the model's output and the observed\n        data given the loss function `loss_fn`.\n\n        **Arguments:**\n\n        - `loss` : A callable that returns a (differentiable) loss. Needs to take (parameters, data) as input and return a scalar tensor.\n        - `optimizer`: A PyTorch optimizer (eg Adam)\n        - `gradient_horizon`: The number of steps to look ahead when computing the gradient. If None, defaults to the number of parameters.\n        - `progress_bar`: Whether to display a progress bar.\n        \"\"\"\n        self.loss_fn = loss\n        self.optimizer = optimizer\n        self.gradient_horizon = gradient_horizon\n        self.progress_bar = progress_bar\n        self.loss = []\n\n    def run(\n        self,\n        data,\n        n_epochs=1000,\n        max_epochs_without_improvement=100,\n        parameters_save_dir=\"best_parameters.pt\",\n    ):\n\"\"\"\n        Runs the SMD algorithm for `n_epochs` epochs.\n\n        **Arguments:**\n\n        - `data`: The observed data.\n        - `n_epochs`: The number of epochs to run.\n        - `max_epochs_without_improvement`: The number of epochs to run without improvement before stopping.\n        - `parameters_save_dir`: The directory to save the best parameters to.\n        \"\"\"\n        best_loss = np.inf\n        epochs_without_improvement = 0\n        if self.progress_bar:\n            iterator = tqdm(range(n_epochs))\n        else:\n            iterator = range(n_epochs)\n        for _ in iterator:\n            self.optimizer.zero_grad()\n            parameters = self.optimizer.param_groups[0][\"params\"][0]\n            loss = self.loss_fn(parameters, data)\n            loss.backward()\n            if loss &lt; best_loss:\n                best_loss = loss.item()\n                epochs_without_improvement = 0\n                torch.save(parameters, parameters_save_dir)\n            else:\n                epochs_without_improvement += 1\n            if self.progress_bar:\n                iterator.set_postfix(\n                    {\n                        \"loss\": loss.item(),\n                        \"best loss\": best_loss,\n                        \"epochs since improv.\": epochs_without_improvement,\n                    }\n                )\n\n            if epochs_without_improvement &gt;= max_epochs_without_improvement:\n                break\n            self.optimizer.step()\n            self.loss.append(loss.item())\n</code></pre>"},{"location":"api/infer/smd/#blackbirds.infer.smd.SMD.__init__","title":"<code>__init__(loss, optimizer, gradient_horizon=None, progress_bar=False)</code>","text":"<p>Simulated Minimum Distance. Finds the point in parameter space that minimizes the distance between the model's output and the observed data given the loss function <code>loss_fn</code>.</p> <p>Arguments:</p> <ul> <li><code>loss</code> : A callable that returns a (differentiable) loss. Needs to take (parameters, data) as input and return a scalar tensor.</li> <li><code>optimizer</code>: A PyTorch optimizer (eg Adam)</li> <li><code>gradient_horizon</code>: The number of steps to look ahead when computing the gradient. If None, defaults to the number of parameters.</li> <li><code>progress_bar</code>: Whether to display a progress bar.</li> </ul> Source code in <code>blackbirds/infer/smd.py</code> <pre><code>def __init__(self, loss, optimizer, gradient_horizon=None, progress_bar=False):\n\"\"\"\n    Simulated Minimum Distance. Finds the point in parameter space that\n    minimizes the distance between the model's output and the observed\n    data given the loss function `loss_fn`.\n\n    **Arguments:**\n\n    - `loss` : A callable that returns a (differentiable) loss. Needs to take (parameters, data) as input and return a scalar tensor.\n    - `optimizer`: A PyTorch optimizer (eg Adam)\n    - `gradient_horizon`: The number of steps to look ahead when computing the gradient. If None, defaults to the number of parameters.\n    - `progress_bar`: Whether to display a progress bar.\n    \"\"\"\n    self.loss_fn = loss\n    self.optimizer = optimizer\n    self.gradient_horizon = gradient_horizon\n    self.progress_bar = progress_bar\n    self.loss = []\n</code></pre>"},{"location":"api/infer/smd/#blackbirds.infer.smd.SMD.run","title":"<code>run(data, n_epochs=1000, max_epochs_without_improvement=100, parameters_save_dir='best_parameters.pt')</code>","text":"<p>Runs the SMD algorithm for <code>n_epochs</code> epochs.</p> <p>Arguments:</p> <ul> <li><code>data</code>: The observed data.</li> <li><code>n_epochs</code>: The number of epochs to run.</li> <li><code>max_epochs_without_improvement</code>: The number of epochs to run without improvement before stopping.</li> <li><code>parameters_save_dir</code>: The directory to save the best parameters to.</li> </ul> Source code in <code>blackbirds/infer/smd.py</code> <pre><code>def run(\n    self,\n    data,\n    n_epochs=1000,\n    max_epochs_without_improvement=100,\n    parameters_save_dir=\"best_parameters.pt\",\n):\n\"\"\"\n    Runs the SMD algorithm for `n_epochs` epochs.\n\n    **Arguments:**\n\n    - `data`: The observed data.\n    - `n_epochs`: The number of epochs to run.\n    - `max_epochs_without_improvement`: The number of epochs to run without improvement before stopping.\n    - `parameters_save_dir`: The directory to save the best parameters to.\n    \"\"\"\n    best_loss = np.inf\n    epochs_without_improvement = 0\n    if self.progress_bar:\n        iterator = tqdm(range(n_epochs))\n    else:\n        iterator = range(n_epochs)\n    for _ in iterator:\n        self.optimizer.zero_grad()\n        parameters = self.optimizer.param_groups[0][\"params\"][0]\n        loss = self.loss_fn(parameters, data)\n        loss.backward()\n        if loss &lt; best_loss:\n            best_loss = loss.item()\n            epochs_without_improvement = 0\n            torch.save(parameters, parameters_save_dir)\n        else:\n            epochs_without_improvement += 1\n        if self.progress_bar:\n            iterator.set_postfix(\n                {\n                    \"loss\": loss.item(),\n                    \"best loss\": best_loss,\n                    \"epochs since improv.\": epochs_without_improvement,\n                }\n            )\n\n        if epochs_without_improvement &gt;= max_epochs_without_improvement:\n            break\n        self.optimizer.step()\n        self.loss.append(loss.item())\n</code></pre>"},{"location":"api/infer/vi/","title":"Variational Inference","text":""},{"location":"api/infer/vi/#blackbirds.infer.vi.VI","title":"<code>VI</code>","text":"<p>Class to handle (Generalized) Variational Inferece.</p> <p>Arguments:</p> <ul> <li><code>loss</code> : A callable that returns a (differentiable) loss. Needs to take (parameters, data) as input and return a scalar tensor.</li> <li><code>prior</code>: The prior distribution.</li> <li><code>posterior_estimator</code>: The variational distribution that approximates the (generalised) posterior.</li> <li><code>w</code>: The weight of the regularisation loss in the total loss.</li> <li><code>initialize_estimator_to_prior</code>: Whether to fit the posterior estimator to the prior before training.</li> <li><code>initialization_lr</code>: The learning rate to use for the initialization.</li> <li><code>gradient_clipping_norm</code>: The norm to which the gradients are clipped.</li> <li><code>optimizer</code>: The optimizer to use for training.</li> <li><code>n_samples_per_epoch</code>: The number of samples to draw from the variational distribution per epoch.</li> <li><code>n_samples_regularisation</code>: The number of samples used to evaluate the regularisation loss.</li> <li><code>diff_mode</code>: The differentiation mode to use. Can be either 'reverse' or 'forward'.</li> <li><code>gradient_estimation_method</code>: The method to use for estimating the gradients of the loss. Can be either 'pathwise' or 'score'.</li> <li><code>jacobian_chunk_size</code> : The number of rows computed at a time for the model Jacobian. Set to None to compute the full Jacobian at once.</li> <li><code>device</code>: The device to use for training.</li> <li><code>progress_bar</code>: Whether to display a progress bar during training.</li> <li><code>progress_info</code> : Whether to display loss data during training.</li> <li><code>log_tensorboard</code>: Whether to log tensorboard data.</li> <li><code>tensorboard_log_dir</code>: The directory to log tensorboard data to.</li> </ul> Source code in <code>blackbirds/infer/vi.py</code> <pre><code>class VI:\n\"\"\"\n    Class to handle (Generalized) Variational Inferece.\n\n    **Arguments:**\n\n    - `loss` : A callable that returns a (differentiable) loss. Needs to take (parameters, data) as input and return a scalar tensor.\n    - `prior`: The prior distribution.\n    - `posterior_estimator`: The variational distribution that approximates the (generalised) posterior.\n    - `w`: The weight of the regularisation loss in the total loss.\n    - `initialize_estimator_to_prior`: Whether to fit the posterior estimator to the prior before training.\n    - `initialization_lr`: The learning rate to use for the initialization.\n    - `gradient_clipping_norm`: The norm to which the gradients are clipped.\n    - `optimizer`: The optimizer to use for training.\n    - `n_samples_per_epoch`: The number of samples to draw from the variational distribution per epoch.\n    - `n_samples_regularisation`: The number of samples used to evaluate the regularisation loss.\n    - `diff_mode`: The differentiation mode to use. Can be either 'reverse' or 'forward'.\n    - `gradient_estimation_method`: The method to use for estimating the gradients of the loss. Can be either 'pathwise' or 'score'.\n    - `jacobian_chunk_size` : The number of rows computed at a time for the model Jacobian. Set to None to compute the full Jacobian at once.\n    - `device`: The device to use for training.\n    - `progress_bar`: Whether to display a progress bar during training.\n    - `progress_info` : Whether to display loss data during training.\n    - `log_tensorboard`: Whether to log tensorboard data.\n    - `tensorboard_log_dir`: The directory to log tensorboard data to.\n    \"\"\"\n\n    def __init__(\n        self,\n        loss: Callable,\n        prior: torch.distributions.Distribution,\n        posterior_estimator: torch.nn.Module,\n        w: float = 1.0,\n        initialize_estimator_to_prior: bool = False,\n        initialization_lr: float = 1e-3,\n        gradient_clipping_norm: float = np.inf,\n        optimizer: Union[torch.optim.Optimizer, None] = None,\n        n_samples_per_epoch: int = 10,\n        n_samples_regularisation: int = 10_000,\n        diff_mode: str = \"reverse\",\n        gradient_estimation_method: str = \"pathwise\",\n        jacobian_chunk_size: Union[int,  None] = None,\n        device: str = \"cpu\",\n        progress_bar: bool = True,\n        progress_info: bool = True,\n        log_tensorboard: bool = False,\n        tensorboard_log_dir: Union[str, None] = None,\n    ):\n        self.loss = loss\n        self.prior = prior\n        self.posterior_estimator = posterior_estimator\n        self.w = w\n        self.initialize_estimator_to_prior = initialize_estimator_to_prior\n        self.initialization_lr = initialization_lr\n        self.gradient_clipping_norm = gradient_clipping_norm\n        if optimizer is None:\n            optimizer = torch.optim.Adam(posterior_estimator.parameters(), lr=1e-3)\n        self.optimizer = optimizer\n        self.n_samples_per_epoch = n_samples_per_epoch\n        self.n_samples_regularisation = n_samples_regularisation\n        self.progress_bar = progress_bar\n        self.progress_info = progress_info\n        self.diff_mode = diff_mode\n        self.gradient_estimation_method = gradient_estimation_method\n        self.jacobian_chunk_size = jacobian_chunk_size\n        self.device = device\n        self.tensorboard_log_dir = tensorboard_log_dir\n        self.log_tensorboard = log_tensorboard\n\n    def step(self, data):\n\"\"\"\n        Performs one training step.\n        \"\"\"\n        if mpi_rank == 0:\n            self.optimizer.zero_grad()\n        # compute and differentiate loss\n        loss = compute_and_differentiate_loss(\n            loss_fn=self.loss,\n            posterior_estimator=self.posterior_estimator,\n            n_samples=self.n_samples_per_epoch,\n            observed_outputs=data,\n            diff_mode=self.diff_mode,\n            gradient_estimation_method=self.gradient_estimation_method,\n            jacobian_chunk_size=self.jacobian_chunk_size,\n            device=self.device,\n        )\n        # compute and differentiate regularisation loss\n        if mpi_rank == 0:\n            if self.w != 0.0:\n                regularisation_loss = self.w * compute_regularisation_loss(\n                    posterior_estimator=self.posterior_estimator,\n                    prior=self.prior,\n                    n_samples=self.n_samples_regularisation,\n                )\n                # differentiate regularisation\n                regularisation_loss.backward()\n            else:\n                regularisation_loss = torch.zeros(1, device=loss.device)\n            # clip gradients\n            torch.nn.utils.clip_grad_norm_(\n                self.posterior_estimator.parameters(), self.gradient_clipping_norm\n            )\n            self.optimizer.step()\n            total_loss = loss + regularisation_loss\n            return total_loss, loss, regularisation_loss\n        return None, None, None\n\n    def initialize_estimator(self, max_epochs_without_improvement=50, atol=1e-2):\n\"\"\"\n        Initialization step where the estimator is fitted to just the prior.\n        \"\"\"\n        epoch = 0\n        if mpi_rank == 0:\n            optimizer = torch.optim.Adam(\n                self.posterior_estimator.parameters(), lr=self.initialization_lr\n            )\n            best_loss = torch.tensor(np.inf)\n            while True:\n                optimizer.zero_grad()\n                loss = compute_regularisation_loss(\n                    posterior_estimator=self.posterior_estimator,\n                    prior=self.prior,\n                    n_samples=self.n_samples_regularisation,\n                )\n                if self.log_tensorboard:\n                    self.writer.add_scalar(\"Loss/init_loss\", loss, epoch)\n                loss.backward()\n                optimizer.step()\n                if loss &lt; best_loss:\n                    best_loss = loss.item()\n                    num_epochs_without_improvement = 0\n                else:\n                    num_epochs_without_improvement += 1\n                if (\n                    num_epochs_without_improvement &gt;= max_epochs_without_improvement\n                    or (loss.abs().item() &lt; atol)\n                ):\n                    break\n                epoch += 1\n\n    def run(\n        self,\n        data: List[torch.Tensor],\n        n_epochs: int,\n        max_epochs_without_improvement: int = 20,\n    ):\n\"\"\"\n        Runs the calibrator for {n_epochs} epochs. Stops if the loss does not improve for {max_epochs_without_improvement} epochs.\n\n        **Arguments:**\n\n        - `data`: The observed data to calibrate against. It must be given as a list of tensors that matches the output of the model.\n        - `n_epochs`: The number of epochs to run the calibrator for.\n        - `max_epochs_without_improvement`: The number of epochs without improvement after which the calibrator stops.\n        \"\"\"\n        if mpi_rank == 0 and self.log_tensorboard:\n            self.writer = SummaryWriter(log_dir=self.tensorboard_log_dir)\n        if self.initialize_estimator_to_prior:\n            self.initialize_estimator()\n            torch.save(\n                self.posterior_estimator.state_dict(), \"estimator_fit_to_prior.pt\"\n            )\n        self.best_loss = torch.tensor(np.inf)\n        self.best_estimator_state_dict = None\n        num_epochs_without_improvement = 0\n        iterator = range(n_epochs)\n        if self.progress_bar and mpi_rank == 0:\n            iterator = tqdm(iterator)\n        self.losses_hist = defaultdict(list)\n        for epoch in iterator:\n            total_loss, loss, regularisation_loss = self.step(data)\n            if mpi_rank == 0:\n                self.losses_hist[\"total\"].append(total_loss.item())\n                self.losses_hist[\"loss\"].append(loss.item())\n                self.losses_hist[\"regularisation\"].append(regularisation_loss.item())\n                if self.log_tensorboard:\n                    self.writer.add_scalar(\"Loss/total\", total_loss, epoch)\n                    self.writer.add_scalar(\"Loss/loss\", loss, epoch)\n                    self.writer.add_scalar(\n                        \"Loss/regularisation\", regularisation_loss, epoch\n                    )\n                torch.save(self.best_estimator_state_dict, \"last_estimator.pt\")\n                if loss &lt; self.best_loss:\n                    self.best_loss = loss\n                    self.best_estimator_state_dict = deepcopy(\n                        self.posterior_estimator.state_dict()\n                    )\n                    torch.save(self.best_estimator_state_dict, \"best_estimator.pt\")\n                    num_epochs_without_improvement = 0\n                else:\n                    num_epochs_without_improvement += 1\n                if self.progress_bar and self.progress_info:\n                    iterator.set_postfix(\n                        {\n                            \"loss\": loss.item(),\n                            \"reg.\": regularisation_loss.item(),\n                            \"total\": total_loss.item(),\n                            \"best loss\": self.best_loss.item(),\n                            \"epochs since improv.\": num_epochs_without_improvement,\n                        }\n                    )\n                if num_epochs_without_improvement &gt;= max_epochs_without_improvement:\n                    logger.info(\n                        \"Stopping early because the loss did not improve for {} epochs.\".format(\n                            max_epochs_without_improvement\n                        )\n                    )\n                    break\n        if mpi_rank == 0 and self.log_tensorboard:\n            self.writer.flush()\n            self.writer.close()\n</code></pre>"},{"location":"api/infer/vi/#blackbirds.infer.vi.VI.initialize_estimator","title":"<code>initialize_estimator(max_epochs_without_improvement=50, atol=0.01)</code>","text":"<p>Initialization step where the estimator is fitted to just the prior.</p> Source code in <code>blackbirds/infer/vi.py</code> <pre><code>def initialize_estimator(self, max_epochs_without_improvement=50, atol=1e-2):\n\"\"\"\n    Initialization step where the estimator is fitted to just the prior.\n    \"\"\"\n    epoch = 0\n    if mpi_rank == 0:\n        optimizer = torch.optim.Adam(\n            self.posterior_estimator.parameters(), lr=self.initialization_lr\n        )\n        best_loss = torch.tensor(np.inf)\n        while True:\n            optimizer.zero_grad()\n            loss = compute_regularisation_loss(\n                posterior_estimator=self.posterior_estimator,\n                prior=self.prior,\n                n_samples=self.n_samples_regularisation,\n            )\n            if self.log_tensorboard:\n                self.writer.add_scalar(\"Loss/init_loss\", loss, epoch)\n            loss.backward()\n            optimizer.step()\n            if loss &lt; best_loss:\n                best_loss = loss.item()\n                num_epochs_without_improvement = 0\n            else:\n                num_epochs_without_improvement += 1\n            if (\n                num_epochs_without_improvement &gt;= max_epochs_without_improvement\n                or (loss.abs().item() &lt; atol)\n            ):\n                break\n            epoch += 1\n</code></pre>"},{"location":"api/infer/vi/#blackbirds.infer.vi.VI.run","title":"<code>run(data, n_epochs, max_epochs_without_improvement=20)</code>","text":"<p>Runs the calibrator for {n_epochs} epochs. Stops if the loss does not improve for {max_epochs_without_improvement} epochs.</p> <p>Arguments:</p> <ul> <li><code>data</code>: The observed data to calibrate against. It must be given as a list of tensors that matches the output of the model.</li> <li><code>n_epochs</code>: The number of epochs to run the calibrator for.</li> <li><code>max_epochs_without_improvement</code>: The number of epochs without improvement after which the calibrator stops.</li> </ul> Source code in <code>blackbirds/infer/vi.py</code> <pre><code>def run(\n    self,\n    data: List[torch.Tensor],\n    n_epochs: int,\n    max_epochs_without_improvement: int = 20,\n):\n\"\"\"\n    Runs the calibrator for {n_epochs} epochs. Stops if the loss does not improve for {max_epochs_without_improvement} epochs.\n\n    **Arguments:**\n\n    - `data`: The observed data to calibrate against. It must be given as a list of tensors that matches the output of the model.\n    - `n_epochs`: The number of epochs to run the calibrator for.\n    - `max_epochs_without_improvement`: The number of epochs without improvement after which the calibrator stops.\n    \"\"\"\n    if mpi_rank == 0 and self.log_tensorboard:\n        self.writer = SummaryWriter(log_dir=self.tensorboard_log_dir)\n    if self.initialize_estimator_to_prior:\n        self.initialize_estimator()\n        torch.save(\n            self.posterior_estimator.state_dict(), \"estimator_fit_to_prior.pt\"\n        )\n    self.best_loss = torch.tensor(np.inf)\n    self.best_estimator_state_dict = None\n    num_epochs_without_improvement = 0\n    iterator = range(n_epochs)\n    if self.progress_bar and mpi_rank == 0:\n        iterator = tqdm(iterator)\n    self.losses_hist = defaultdict(list)\n    for epoch in iterator:\n        total_loss, loss, regularisation_loss = self.step(data)\n        if mpi_rank == 0:\n            self.losses_hist[\"total\"].append(total_loss.item())\n            self.losses_hist[\"loss\"].append(loss.item())\n            self.losses_hist[\"regularisation\"].append(regularisation_loss.item())\n            if self.log_tensorboard:\n                self.writer.add_scalar(\"Loss/total\", total_loss, epoch)\n                self.writer.add_scalar(\"Loss/loss\", loss, epoch)\n                self.writer.add_scalar(\n                    \"Loss/regularisation\", regularisation_loss, epoch\n                )\n            torch.save(self.best_estimator_state_dict, \"last_estimator.pt\")\n            if loss &lt; self.best_loss:\n                self.best_loss = loss\n                self.best_estimator_state_dict = deepcopy(\n                    self.posterior_estimator.state_dict()\n                )\n                torch.save(self.best_estimator_state_dict, \"best_estimator.pt\")\n                num_epochs_without_improvement = 0\n            else:\n                num_epochs_without_improvement += 1\n            if self.progress_bar and self.progress_info:\n                iterator.set_postfix(\n                    {\n                        \"loss\": loss.item(),\n                        \"reg.\": regularisation_loss.item(),\n                        \"total\": total_loss.item(),\n                        \"best loss\": self.best_loss.item(),\n                        \"epochs since improv.\": num_epochs_without_improvement,\n                    }\n                )\n            if num_epochs_without_improvement &gt;= max_epochs_without_improvement:\n                logger.info(\n                    \"Stopping early because the loss did not improve for {} epochs.\".format(\n                        max_epochs_without_improvement\n                    )\n                )\n                break\n    if mpi_rank == 0 and self.log_tensorboard:\n        self.writer.flush()\n        self.writer.close()\n</code></pre>"},{"location":"api/infer/vi/#blackbirds.infer.vi.VI.step","title":"<code>step(data)</code>","text":"<p>Performs one training step.</p> Source code in <code>blackbirds/infer/vi.py</code> <pre><code>def step(self, data):\n\"\"\"\n    Performs one training step.\n    \"\"\"\n    if mpi_rank == 0:\n        self.optimizer.zero_grad()\n    # compute and differentiate loss\n    loss = compute_and_differentiate_loss(\n        loss_fn=self.loss,\n        posterior_estimator=self.posterior_estimator,\n        n_samples=self.n_samples_per_epoch,\n        observed_outputs=data,\n        diff_mode=self.diff_mode,\n        gradient_estimation_method=self.gradient_estimation_method,\n        jacobian_chunk_size=self.jacobian_chunk_size,\n        device=self.device,\n    )\n    # compute and differentiate regularisation loss\n    if mpi_rank == 0:\n        if self.w != 0.0:\n            regularisation_loss = self.w * compute_regularisation_loss(\n                posterior_estimator=self.posterior_estimator,\n                prior=self.prior,\n                n_samples=self.n_samples_regularisation,\n            )\n            # differentiate regularisation\n            regularisation_loss.backward()\n        else:\n            regularisation_loss = torch.zeros(1, device=loss.device)\n        # clip gradients\n        torch.nn.utils.clip_grad_norm_(\n            self.posterior_estimator.parameters(), self.gradient_clipping_norm\n        )\n        self.optimizer.step()\n        total_loss = loss + regularisation_loss\n        return total_loss, loss, regularisation_loss\n    return None, None, None\n</code></pre>"},{"location":"api/infer/vi/#blackbirds.infer.vi.compute_and_differentiate_loss","title":"<code>compute_and_differentiate_loss(loss_fn, posterior_estimator, n_samples, observed_outputs, diff_mode='reverse', gradient_estimation_method='pathwise', jacobian_chunk_size=None, device='cpu')</code>","text":"<p>Computes and differentiates the loss according to the chosen gradient estimation method and automatic differentiation mechanism. Arguments:</p> <ul> <li><code>loss_fn</code>: loss function</li> <li><code>posterior_estimator</code>: posterior estimator, must implement a sample and a log_prob method</li> <li><code>n_samples</code>: number of samples</li> <li><code>observed_outputs</code>: observed outputs</li> <li><code>diff_mode</code>: differentiation mode can be \"reverse\" or \"forward\"</li> <li><code>gradient_estimation_method</code>: gradient estimation method can be \"pathwise\" or \"score\"</li> <li><code>jacobian_chunk_size</code>: chunk size for the Jacobian computation (set None to get maximum chunk size)</li> <li><code>device</code>: device to use for the computation</li> </ul> Source code in <code>blackbirds/infer/vi.py</code> <pre><code>def compute_and_differentiate_loss(\n    loss_fn: Callable,\n    posterior_estimator: torch.nn.Module,\n    n_samples: int,\n    observed_outputs: list[torch.Tensor],\n    diff_mode: str = \"reverse\",\n    gradient_estimation_method: str = \"pathwise\",\n    jacobian_chunk_size: Union[int, None] = None,\n    device: str = \"cpu\",\n):\nr\"\"\"Computes and differentiates the loss according to the chosen gradient estimation method\n    and automatic differentiation mechanism.\n    **Arguments:**\n\n    - `loss_fn`: loss function\n    - `posterior_estimator`: posterior estimator, must implement a sample and a log_prob method\n    - `n_samples`: number of samples\n    - `observed_outputs`: observed outputs\n    - `diff_mode`: differentiation mode can be \"reverse\" or \"forward\"\n    - `gradient_estimation_method`: gradient estimation method can be \"pathwise\" or \"score\"\n    - `jacobian_chunk_size`: chunk size for the Jacobian computation (set None to get maximum chunk size)\n    - `device`: device to use for the computation\n    \"\"\"\n    if gradient_estimation_method == \"pathwise\":\n        (\n            parameters,\n            loss,\n            jacobians,\n        ) = compute_loss_and_jacobian_pathwise(\n            loss_fn=loss_fn,\n            posterior_estimator=posterior_estimator,\n            observed_outputs=observed_outputs,\n            n_samples=n_samples,\n            diff_mode=diff_mode,\n            device=device,\n            jacobian_chunk_size=jacobian_chunk_size,\n        )\n        if mpi_rank == 0:\n            _differentiate_loss_pathwise(parameters, jacobians)\n    elif gradient_estimation_method == \"score\":\n        loss = compute_and_differentiate_loss_score(\n            loss_fn=loss_fn,\n            posterior_estimator=posterior_estimator,\n            observed_outputs=observed_outputs,\n            n_samples=n_samples,\n            device=device,\n        )\n    else:\n        raise ValueError(\n            f\"Unknown gradient estimation method {gradient_estimation_method}.\"\n        )\n    return loss\n</code></pre>"},{"location":"api/infer/vi/#blackbirds.infer.vi.compute_and_differentiate_loss_score","title":"<code>compute_and_differentiate_loss_score(loss_fn, posterior_estimator, n_samples, observed_outputs, device='cpu')</code>","text":"<p>Computes the loss and the jacobian of the loss for each sample using a differentiable simulator. That is, we compute</p> \\[ \\eta = \\nabla_\\psi \\mathbb{E}_{\\psi \\sim p(\\theta)} \\left[ \\mathcal{L}(\\theta) \\right], \\] <p>by performing the score gradient</p> \\[ \\eta \\approx \\frac{1}{N} \\sum_{i=1}^N \\mathcal{L}(\\theta_i) \\nabla_\\psi \\log p\\left(\\theta_i | \\psi\\right). \\] <p>The jacobian is computed using the forward or reverse mode differentiation and the computation is parallelized across the available devices.</p> <p>Arguments:</p> <ul> <li><code>loss_fn</code>: loss function</li> <li><code>posterior_estimator</code>: posterior estimator, must implement a sample and a log_prob method</li> <li><code>n_samples</code>: number of samples</li> <li><code>observed_outputs</code>: observed outputs</li> <li><code>device</code>: device to use for the computation</li> </ul> Source code in <code>blackbirds/infer/vi.py</code> <pre><code>def compute_and_differentiate_loss_score(\n    loss_fn: Callable,\n    posterior_estimator: torch.nn.Module,\n    n_samples: int,\n    observed_outputs: list[torch.Tensor],\n    device: str = \"cpu\",\n):\nr\"\"\"Computes the loss and the jacobian of the loss for each sample using a differentiable simulator. That is, we compute\n\n    $$\n    \\eta = \\nabla_\\psi \\mathbb{E}_{\\psi \\sim p(\\theta)} \\left[ \\mathcal{L}(\\theta) \\right],\n    $$\n\n    by performing the score gradient\n\n    $$\n    \\eta \\approx \\frac{1}{N} \\sum_{i=1}^N \\mathcal{L}(\\theta_i) \\nabla_\\psi \\log p\\left(\\theta_i | \\psi\\right).\n    $$\n\n    The jacobian is computed using the forward or reverse mode differentiation and the computation is parallelized\n    across the available devices.\n\n    **Arguments:**\n\n    - `loss_fn`: loss function\n    - `posterior_estimator`: posterior estimator, must implement a sample and a log_prob method\n    - `n_samples`: number of samples\n    - `observed_outputs`: observed outputs\n    - `device`: device to use for the computation\n    \"\"\"\n    # sample parameters and scatter them across devices\n    _, params_list_comm, logprobs_list = _sample_and_scatter_parameters(\n        posterior_estimator, n_samples\n    )\n    # make each rank compute the loss for its parameters\n    loss_per_parameter = []\n    indices_per_rank = []  # need to keep track of which parameter has which loss\n    for i in range(mpi_rank, len(params_list_comm), mpi_size):\n        params = torch.tensor(params_list_comm[i], device=device)\n        loss_i = loss_fn(params, observed_outputs)\n        loss_per_parameter.append(loss_i.detach().cpu().numpy())\n        indices_per_rank.append(i)\n    # gather the losses from all ranks\n    if mpi_size &gt; 1:\n        loss_per_parameter = mpi_comm.gather(loss_per_parameter, root=0)\n        indices_per_rank = mpi_comm.gather(indices_per_rank, root=0)\n    else:\n        loss_per_parameter = [loss_per_parameter]\n        indices_per_rank = [indices_per_rank]\n    # compute the loss times the logprob of each parameter in rank 0\n    if mpi_rank == 0:\n        loss_per_parameter = list(chain(*loss_per_parameter))\n        indices = list(chain(*indices_per_rank))\n        logprobs_list = logprobs_list[indices]\n        params_list_comm = params_list_comm[indices]\n        to_backprop = 0.0\n        total_loss = 0.0\n        n_samples_non_nan = 0\n        for param, loss_i, param_logprob in zip(\n            params_list_comm, loss_per_parameter, logprobs_list\n        ):\n            loss_i = torch.tensor(loss_i, device=device)\n            if np.isnan(loss_i):  # no parameter was non-nan\n                continue\n            lp = posterior_estimator.log_prob(torch.tensor(param.reshape(1, -1)))\n            to_backprop += loss_i * lp\n            total_loss += loss_i\n            n_samples_non_nan += 1\n        to_backprop = to_backprop / n_samples_non_nan\n        total_loss = total_loss / n_samples_non_nan\n        # differentiate through the posterior estimator\n        to_backprop.backward()\n        return total_loss\n    return None\n</code></pre>"},{"location":"api/infer/vi/#blackbirds.infer.vi.compute_loss_and_jacobian_pathwise","title":"<code>compute_loss_and_jacobian_pathwise(loss_fn, posterior_estimator, n_samples, observed_outputs, diff_mode='reverse', jacobian_chunk_size=None, device='cpu')</code>","text":"<p>Computes the loss and the jacobian of the loss for each sample using a differentiable simulator. That is, we compute</p> \\[ \\eta = \\nabla_\\psi \\mathbb{E}_{p(\\theta | \\psi)} \\left[ \\mathcal{L}(\\theta) \\right], \\] <p>by performing the pathwise gradient (reparameterization trick),</p> \\[ \\eta \\approx \\frac{1}{N} \\sum_{i=1}^N \\nabla_\\psi \\mathcal{L}(\\theta_i(\\psi)). \\] <p>The jacobian is computed using the forward or reverse mode differentiation and the computation is parallelized across the available devices.</p> <p>Arguments:</p> <ul> <li><code>loss_fn</code>: loss function</li> <li><code>posterior_estimator</code>: Object that implements the <code>sample</code> method computing a parameter and its log_prob</li> <li><code>n_samples</code>: number of samples</li> <li><code>observed_outputs</code>: observed outputs</li> <li><code>diff_mode</code>: differentiation mode can be \"reverse\" or \"forward\"</li> <li><code>jacobian_chunk_size</code>: chunk size for the Jacobian computation (set None to get maximum chunk size)</li> <li><code>device</code>: device to use for the computation</li> </ul> Source code in <code>blackbirds/infer/vi.py</code> <pre><code>def compute_loss_and_jacobian_pathwise(\n    loss_fn: Callable,\n    posterior_estimator: Callable,\n    n_samples: int,\n    observed_outputs: list[torch.Tensor],\n    diff_mode: str = \"reverse\",\n    jacobian_chunk_size: Union[int, None] = None,\n    device: str = \"cpu\",\n):\nr\"\"\"Computes the loss and the jacobian of the loss for each sample using a differentiable simulator. That is, we compute\n\n    $$\n    \\eta = \\nabla_\\psi \\mathbb{E}_{p(\\theta | \\psi)} \\left[ \\mathcal{L}(\\theta) \\right],\n    $$\n\n    by performing the pathwise gradient (reparameterization trick),\n\n    $$\n    \\eta \\approx \\frac{1}{N} \\sum_{i=1}^N \\nabla_\\psi \\mathcal{L}(\\theta_i(\\psi)).\n    $$\n\n    The jacobian is computed using the forward or reverse mode differentiation and the computation is parallelized\n    across the available devices.\n\n    **Arguments:**\n\n    - `loss_fn`: loss function\n    - `posterior_estimator`: Object that implements the `sample` method computing a parameter and its log_prob\n    - `n_samples`: number of samples\n    - `observed_outputs`: observed outputs\n    - `diff_mode`: differentiation mode can be \"reverse\" or \"forward\"\n    - `jacobian_chunk_size`: chunk size for the Jacobian computation (set None to get maximum chunk size)\n    - `device`: device to use for the computation\n    \"\"\"\n    # sample parameters and scatter them across devices\n    params_list, params_list_comm, _ = _sample_and_scatter_parameters(\n        posterior_estimator, n_samples\n    )\n    # select forward or reverse jacobian calculator\n    if diff_mode == \"reverse\":\n        jacobian_diff_mode = torch.func.jacrev\n    else:\n        jacobian_diff_mode = lambda **kwargs: jacfwd(randomness=\"same\", **kwargs)\n\n    # define loss to differentiate\n    def loss_aux(params):\n        loss_v = loss_fn(params, observed_outputs)\n        return loss_v, loss_v  # need double return for jacobian calculation.\n\n    jacobian_calculator = jacobian_diff_mode(\n        func=loss_aux,\n        argnums=0,\n        has_aux=True,\n        chunk_size=jacobian_chunk_size,\n    )\n    # make each rank compute the loss for its parameters\n    loss = 0\n    jacobians_per_rank = []\n    indices_per_rank = []  # need to keep track of which parameter has which jacobian\n    for i in range(mpi_rank, len(params_list_comm), mpi_size):\n        params = torch.tensor(params_list_comm[i], device=device)\n        jacobian, loss_i = jacobian_calculator(params)\n        if torch.isnan(loss_i) or torch.isnan(jacobian).any():\n            continue\n        loss += loss_i\n        jacobians_per_rank.append(torch.tensor(jacobian.cpu().numpy()))\n        indices_per_rank.append(i)\n    # gather the jacobians and parameters from all ranks\n    if mpi_size &gt; 1:\n        jacobians_per_rank = mpi_comm.gather(jacobians_per_rank, root=0)\n        indices_per_rank = mpi_comm.gather(indices_per_rank, root=0)\n    else:\n        jacobians_per_rank = [jacobians_per_rank]\n        indices_per_rank = [indices_per_rank]\n    if mpi_comm is not None:\n        losses = mpi_comm.gather(loss, root=0)\n        if mpi_rank == 0:\n            loss = sum([l.cpu() for l in losses if l != 0])\n            if type(loss) == int:\n                loss = torch.tensor(loss, device=device)\n    if mpi_rank == 0:\n        jacobians = list(chain(*jacobians_per_rank))\n        indices = list(chain(*indices_per_rank))\n        parameters = params_list[indices]\n        loss = loss / len(parameters)\n        return parameters, loss, jacobians\n    else:\n        return [], 0.0, []\n</code></pre>"},{"location":"api/infer/vi/#blackbirds.infer.vi.compute_regularisation_loss","title":"<code>compute_regularisation_loss(posterior_estimator, prior, n_samples)</code>","text":"<p>Estimates the KL divergence between the posterior and the prior using n_samples through Monte Carlo using</p> \\[ \\mathbb{E}_{q(z|x)}[\\log q(z|x) - \\log p(z)] \\approx \\frac{1}{N} \\sum_{i=1}^N \\left(\\log q(z_i|x) - \\log p(z_i)\\right) \\] <p>Arguments:</p> <ul> <li><code>posterior_estimator</code>: The posterior distribution.</li> <li><code>prior</code>: The prior distribution.</li> <li><code>n_samples</code>: The number of samples to use for the Monte Carlo estimate.</li> </ul> <p>Example</p> <pre><code>    import torch\n    from blackbirds.regularisation import compute_regularisation\n    # define two normal distributions\n    dist1 = torch.distributions.Normal(0, 1)\n    dist2 = torch.distributions.Normal(0, 1)\n    compute_regularisation(dist1, dist2, 1000)\n    # tensor(0.)\n    dist1 = torch.distributions.Normal(0, 1)\n    dist2 = torch.distributions.Normal(1, 1)\n    compute_regularisation(dist1, dist2, 1000)\n    # tensor(0.5)\n</code></pre> Source code in <code>blackbirds/infer/vi.py</code> <pre><code>def compute_regularisation_loss(\n    posterior_estimator: torch.nn.Module,\n    prior: torch.distributions.Distribution,\n    n_samples: int,\n):\nr\"\"\"Estimates the KL divergence between the posterior and the prior using n_samples through Monte Carlo using\n\n    $$\n    \\mathbb{E}_{q(z|x)}[\\log q(z|x) - \\log p(z)] \\approx \\frac{1}{N} \\sum_{i=1}^N \\left(\\log q(z_i|x) - \\log p(z_i)\\right)\n    $$\n\n    **Arguments**:\n\n    - `posterior_estimator`: The posterior distribution.\n    - `prior`: The prior distribution.\n    - `n_samples`: The number of samples to use for the Monte Carlo estimate.\n\n    !!! example\n        ```python\n            import torch\n            from blackbirds.regularisation import compute_regularisation\n            # define two normal distributions\n            dist1 = torch.distributions.Normal(0, 1)\n            dist2 = torch.distributions.Normal(0, 1)\n            compute_regularisation(dist1, dist2, 1000)\n            # tensor(0.)\n            dist1 = torch.distributions.Normal(0, 1)\n            dist2 = torch.distributions.Normal(1, 1)\n            compute_regularisation(dist1, dist2, 1000)\n            # tensor(0.5)\n        ```\n    \"\"\"\n    # sample from the posterior\n    z, log_prob_posterior = posterior_estimator.sample(n_samples)\n    # compute the log probability of the samples under the prior\n    # log_prob_posterior = posterior_estimator.log_prob(z)\n    log_prob_prior = prior.log_prob(z)\n    # compute the Monte Carlo estimate of the KL divergence\n    kl_divergence = (log_prob_posterior - log_prob_prior).mean()\n    # kl_divergence = torch.clamp(kl_divergence, min=0.0, max=1)\n    return kl_divergence\n</code></pre>"},{"location":"api/models/brock_hommes/","title":"Brock &amp; Hommes","text":""},{"location":"api/models/brock_hommes/#blackbirds.models.brock_hommes.BrockHommes","title":"<code>BrockHommes</code>","text":"<p>             Bases: <code>Model</code></p> <p>Differentiable implementation of the Brock and Hommes (1998) model. See equations (39) and (40) of https://arxiv.org/pdf/2202.00625.pdf for reference.</p> <p>Arguments:</p> <ul> <li><code>n_timesteps</code>: Number of timesteps to simulate. Default: 100.</li> </ul> Source code in <code>blackbirds/models/brock_hommes.py</code> <pre><code>class BrockHommes(Model):\nr\"\"\"Differentiable implementation of the Brock and Hommes (1998) model. See equations (39) and (40)\n    of https://arxiv.org/pdf/2202.00625.pdf for reference.\n\n    **Arguments:**\n\n    - `n_timesteps`: Number of timesteps to simulate. Default: 100.\n    \"\"\"\n\n    def __init__(self, n_timesteps=100, device=\"cpu\"):\n        super().__init__()\n        self.n_timesteps = n_timesteps\n        self._eps = torch.distributions.normal.Normal(\n            torch.tensor([0.0], device=device), torch.tensor([1.0], device=device)\n        )\n        self.device = device\n\n    def initialize(self, params):\n        return torch.zeros((3, 1))\n\n    def trim_time_series(self, x):\n        return x[-3:]\n\n    def step(self, params, x):\nr\"\"\"\n        Runs the model forward for one time-step. Parameters follow the order: log_beta, g1, g2, g3, g4, b1, b2, b3, b4, log_sigma, log_r\n\n        **Arguments:**\n\n        - `params`: A list of parameters. Parameters follow the order: log_beta, g1, g2, g3, g4, b1, b2, b3, b4, log_sigma, log_r\n        - `x`: The current state of the model.\n\n        !!! danger\n            beta, sigma, and r are given in log.\n        \"\"\"\n        beta = torch.exp(params[0])\n        g = params[1:5]\n        b = params[5:9]\n        sigma = torch.exp(params[-2])\n        r = torch.exp(params[-1])\n        R = 1.0 + r\n        g = soft_maximum(soft_minimum(g, torch.tensor(1.0), 2), torch.tensor(1e-3), 2)\n\n        epsilon = self._eps.rsample()\n        exponent = beta * (x[-1] - R * x[-2]) * (g * x[-3] + b - R * x[-2])\n        norm_exponentiated = torch.nn.Softmax(dim=-1)(exponent)\n        mean = (norm_exponentiated * (g * x[-1] + b)).sum()\n        x_t = (mean + epsilon * sigma) / R\n        return x_t.reshape(1, -1)\n\n    def observe(self, x):\n        return [x.flatten()]\n</code></pre>"},{"location":"api/models/brock_hommes/#blackbirds.models.brock_hommes.BrockHommes.step","title":"<code>step(params, x)</code>","text":"<p>Runs the model forward for one time-step. Parameters follow the order: log_beta, g1, g2, g3, g4, b1, b2, b3, b4, log_sigma, log_r</p> <p>Arguments:</p> <ul> <li><code>params</code>: A list of parameters. Parameters follow the order: log_beta, g1, g2, g3, g4, b1, b2, b3, b4, log_sigma, log_r</li> <li><code>x</code>: The current state of the model.</li> </ul> <p>Danger</p> <p>beta, sigma, and r are given in log.</p> Source code in <code>blackbirds/models/brock_hommes.py</code> <pre><code>def step(self, params, x):\nr\"\"\"\n    Runs the model forward for one time-step. Parameters follow the order: log_beta, g1, g2, g3, g4, b1, b2, b3, b4, log_sigma, log_r\n\n    **Arguments:**\n\n    - `params`: A list of parameters. Parameters follow the order: log_beta, g1, g2, g3, g4, b1, b2, b3, b4, log_sigma, log_r\n    - `x`: The current state of the model.\n\n    !!! danger\n        beta, sigma, and r are given in log.\n    \"\"\"\n    beta = torch.exp(params[0])\n    g = params[1:5]\n    b = params[5:9]\n    sigma = torch.exp(params[-2])\n    r = torch.exp(params[-1])\n    R = 1.0 + r\n    g = soft_maximum(soft_minimum(g, torch.tensor(1.0), 2), torch.tensor(1e-3), 2)\n\n    epsilon = self._eps.rsample()\n    exponent = beta * (x[-1] - R * x[-2]) * (g * x[-3] + b - R * x[-2])\n    norm_exponentiated = torch.nn.Softmax(dim=-1)(exponent)\n    mean = (norm_exponentiated * (g * x[-1] + b)).sum()\n    x_t = (mean + epsilon * sigma) / R\n    return x_t.reshape(1, -1)\n</code></pre>"},{"location":"api/models/rama_cont/","title":"Rama Cont","text":""},{"location":"api/models/rama_cont/#blackbirds.models.rama_cont.RamaCont","title":"<code>RamaCont</code>","text":"<p>             Bases: <code>Model</code></p> Source code in <code>blackbirds/models/rama_cont.py</code> <pre><code>class RamaCont(Model):\n    def __init__(self, n_agents, n_timesteps, s, sigmoid_k):\nr\"\"\"\n        Implementation of the Rama Cont model from Rama Cont (2005).\n\n        **Arguments:**\n\n        - `n_agents`: Number of agents\n        - `n_timesteps`: Number of timesteps\n        - `s`: Probability of updating the threshold $\\nu_i$.\n        - `sigmoid_k`: Steepness of the sigmoid function.\n        \"\"\"\n        super().__init__()\n        self.n_agents = n_agents\n        self.n_timesteps = n_timesteps\n        self.s = s\n        self.sigmoid_k = sigmoid_k\n\n    def initialize(self, params):\n        nu_0 = torch.distributions.LogNormal(params[0], params[1]).rsample(\n            (self.n_agents,)\n        )\n        epsilon_t = torch.zeros(self.n_agents)\n        order = self.compute_order(epsilon_t, nu_0)\n        eta = params[3]\n        returns = self.compute_returns(order, eta) * torch.ones(self.n_agents)\n        x = torch.vstack((nu_0, epsilon_t, returns))\n        return x.reshape(1, 3, self.n_agents)\n\n    def step(self, params, x):\n        # draw epsilon_t from normal distribution\n        sigma = params[2]\n        epsilon_t = torch.distributions.Normal(0, sigma).rsample()\n        # compute order\n        nu_t = x[-1, 0, :]\n        order = self.compute_order(epsilon_t, nu_t)\n        # compute returns\n        eta = params[3]\n        returns = self.compute_returns(order, eta)\n        # update nu_t\n        new_nu_t = self.compute_new_nu_t(nu_t, self.s, returns)\n        x = torch.vstack(\n            (\n                new_nu_t,\n                epsilon_t * torch.ones(self.n_agents),\n                returns * torch.ones(self.n_agents),\n            )\n        )\n        return x.reshape(1, 3, self.n_agents)\n\n    def observe(self, x):\n        return [x[:, 2, 0]]\n\n    def compute_order_soft(self, epsilon_t, nu_t):\n        return torch.sigmoid(self.sigmoid_k * (epsilon_t - nu_t)) - torch.sigmoid(\n            self.sigmoid_k * (-nu_t - epsilon_t)\n        )\n\n    def compute_order_hard(self, epsilon_t, nu_t):\n        return (epsilon_t &gt; nu_t).float() - (epsilon_t &lt; -nu_t).float()\n\n    def compute_order(self, epsilon_t, nu_t):\n\"\"\"\n        We do a trick similar to the gumbel-softmax.\n        \"\"\"\n        soft = self.compute_order_soft(epsilon_t, nu_t)\n        return self.compute_order_hard(epsilon_t, nu_t) + soft - soft.detach()\n\n    def compute_returns(self, order, eta):\n        return 1.0 / (self.n_agents * eta) * order.sum()\n\n    def compute_new_nu_t(self, nu_t, s, returns):\n        probs = s * torch.ones(self.n_agents)\n        probs = torch.vstack((probs, 1.0 - probs)).transpose(0, 1)\n        q = torch.nn.functional.gumbel_softmax(probs.log(), tau=0.1, hard=True)[:, 0]\n        return torch.abs(returns) * q + (1 - q) * nu_t\n\n    def trim_time_series(self, x):\n        return x\n</code></pre>"},{"location":"api/models/rama_cont/#blackbirds.models.rama_cont.RamaCont.__init__","title":"<code>__init__(n_agents, n_timesteps, s, sigmoid_k)</code>","text":"<p>Implementation of the Rama Cont model from Rama Cont (2005).</p> <p>Arguments:</p> <ul> <li><code>n_agents</code>: Number of agents</li> <li><code>n_timesteps</code>: Number of timesteps</li> <li><code>s</code>: Probability of updating the threshold \\(\\nu_i\\).</li> <li><code>sigmoid_k</code>: Steepness of the sigmoid function.</li> </ul> Source code in <code>blackbirds/models/rama_cont.py</code> <pre><code>def __init__(self, n_agents, n_timesteps, s, sigmoid_k):\nr\"\"\"\n    Implementation of the Rama Cont model from Rama Cont (2005).\n\n    **Arguments:**\n\n    - `n_agents`: Number of agents\n    - `n_timesteps`: Number of timesteps\n    - `s`: Probability of updating the threshold $\\nu_i$.\n    - `sigmoid_k`: Steepness of the sigmoid function.\n    \"\"\"\n    super().__init__()\n    self.n_agents = n_agents\n    self.n_timesteps = n_timesteps\n    self.s = s\n    self.sigmoid_k = sigmoid_k\n</code></pre>"},{"location":"api/models/rama_cont/#blackbirds.models.rama_cont.RamaCont.compute_order","title":"<code>compute_order(epsilon_t, nu_t)</code>","text":"<p>We do a trick similar to the gumbel-softmax.</p> Source code in <code>blackbirds/models/rama_cont.py</code> <pre><code>def compute_order(self, epsilon_t, nu_t):\n\"\"\"\n    We do a trick similar to the gumbel-softmax.\n    \"\"\"\n    soft = self.compute_order_soft(epsilon_t, nu_t)\n    return self.compute_order_hard(epsilon_t, nu_t) + soft - soft.detach()\n</code></pre>"},{"location":"api/models/random_walk/","title":"Random Walk","text":""},{"location":"api/models/random_walk/#blackbirds.models.random_walk.RandomWalk","title":"<code>RandomWalk</code>","text":"<p>             Bases: <code>Model</code></p> Source code in <code>blackbirds/models/random_walk.py</code> <pre><code>class RandomWalk(Model):\n    def __init__(self, n_timesteps, tau_softmax=0.1):\nr\"\"\"Implements a differentiable random walk.\n\n        $$\n            X_t = \\sum_{i=1}^t (2\\eta - 1),\n        $$\n\n        where\n\n        $$\n        \\eta \\sim \\text{Bernoulli}(p).\n        $$\n\n        **Arguments**:\n\n        - `n_timesteps` (int): Number of timesteps to simulate.\n        - `tau_softmax` (float): Temperature parameter for the Gumbel-Softmax\n        \"\"\"\n        super().__init__()\n        self.n_timesteps = n_timesteps\n        self.tau_softmax = tau_softmax\n\n    def initialize(self, params):\n        return torch.zeros(1).reshape(1, 1)\n\n    def trim_time_series(self, x):\n        return x[-1:]\n\n    def step(self, params, x):\n\"\"\"Simulates a random walk step using the Gumbel-Softmax trick.\n\n        **Arguments:**\n\n        - `params`: a tensor of shape (1,) containing the logit probability of moving forward at each timestep.\n        - `x`: a tensor of shape (n,) containing the time-series of positions.\n\n        !!! danger\n            probability is given in logit, so the input is transformed using the sigmoid function.\n        \"\"\"\n        p = torch.sigmoid(params)\n        logits = torch.vstack((p, 1 - p)).log()\n        step = torch.nn.functional.gumbel_softmax(\n            logits, dim=0, tau=self.tau_softmax, hard=True\n        )\n        return (x[-1] + step[0] - step[1]).reshape(1, 1)\n\n    def observe(self, x):\n        return [x]\n</code></pre>"},{"location":"api/models/random_walk/#blackbirds.models.random_walk.RandomWalk.__init__","title":"<code>__init__(n_timesteps, tau_softmax=0.1)</code>","text":"<p>Implements a differentiable random walk.</p> \\[     X_t = \\sum_{i=1}^t (2\\eta - 1), \\] <p>where</p> \\[ \\eta \\sim \\text{Bernoulli}(p). \\] <p>Arguments:</p> <ul> <li><code>n_timesteps</code> (int): Number of timesteps to simulate.</li> <li><code>tau_softmax</code> (float): Temperature parameter for the Gumbel-Softmax</li> </ul> Source code in <code>blackbirds/models/random_walk.py</code> <pre><code>def __init__(self, n_timesteps, tau_softmax=0.1):\nr\"\"\"Implements a differentiable random walk.\n\n    $$\n        X_t = \\sum_{i=1}^t (2\\eta - 1),\n    $$\n\n    where\n\n    $$\n    \\eta \\sim \\text{Bernoulli}(p).\n    $$\n\n    **Arguments**:\n\n    - `n_timesteps` (int): Number of timesteps to simulate.\n    - `tau_softmax` (float): Temperature parameter for the Gumbel-Softmax\n    \"\"\"\n    super().__init__()\n    self.n_timesteps = n_timesteps\n    self.tau_softmax = tau_softmax\n</code></pre>"},{"location":"api/models/random_walk/#blackbirds.models.random_walk.RandomWalk.step","title":"<code>step(params, x)</code>","text":"<p>Simulates a random walk step using the Gumbel-Softmax trick.</p> <p>Arguments:</p> <ul> <li><code>params</code>: a tensor of shape (1,) containing the logit probability of moving forward at each timestep.</li> <li><code>x</code>: a tensor of shape (n,) containing the time-series of positions.</li> </ul> <p>Danger</p> <p>probability is given in logit, so the input is transformed using the sigmoid function.</p> Source code in <code>blackbirds/models/random_walk.py</code> <pre><code>def step(self, params, x):\n\"\"\"Simulates a random walk step using the Gumbel-Softmax trick.\n\n    **Arguments:**\n\n    - `params`: a tensor of shape (1,) containing the logit probability of moving forward at each timestep.\n    - `x`: a tensor of shape (n,) containing the time-series of positions.\n\n    !!! danger\n        probability is given in logit, so the input is transformed using the sigmoid function.\n    \"\"\"\n    p = torch.sigmoid(params)\n    logits = torch.vstack((p, 1 - p)).log()\n    step = torch.nn.functional.gumbel_softmax(\n        logits, dim=0, tau=self.tau_softmax, hard=True\n    )\n    return (x[-1] + step[0] - step[1]).reshape(1, 1)\n</code></pre>"},{"location":"api/models/sir/","title":"SIR","text":""},{"location":"api/models/sir/#blackbirds.models.sir.SIR","title":"<code>SIR</code>","text":"<p>             Bases: <code>Model</code></p> Source code in <code>blackbirds/models/sir.py</code> <pre><code>class SIR(Model):\n    def __init__(self, graph: networkx.Graph, n_timesteps: int, device: str = \"cpu\"):\n\"\"\"\n        Implements a differentiable SIR model on a graph.\n\n        **Arguments:**\n\n        - `graph`: a networkx graph\n        - `n_timesteps`: the number of timesteps to run the model for\n        - `device` : device to use (eg. \"cpu\" or \"cuda:0\")\n        \"\"\"\n        super().__init__()\n        self.n_timesteps = n_timesteps\n        # convert graph from networkx to pytorch geometric\n        self.graph = torch_geometric.utils.convert.from_networkx(graph).to(device)\n        self.mp = SIRMessagePassing(aggr=\"add\", node_dim=-1)\n\n    def sample_bernoulli_gs(self, probs: torch.Tensor, tau: float = 0.1):\n\"\"\"\n        Samples from a Bernoulli distribution in a diferentiable way using Gumble-Softmax\n\n        **Arguments:**\n\n        - probs: a tensor of shape (n,) containing the probabilities of success for each trial\n        - tau: the temperature of the Gumble-Softmax distribution\n        \"\"\"\n        logits = torch.vstack((probs, 1 - probs)).T.log()\n        gs_samples = torch.nn.functional.gumbel_softmax(logits, tau=tau, hard=True)\n        return gs_samples[:, 0]\n\n    def trim_time_series(self, x):\n        return x[-1:]\n\n    def initialize(self, params: torch.Tensor):\n\"\"\"\n        Initializes the model setting the adequate number of initial infections.\n\n        **Arguments**:\n\n        - params: a tensor of shape (3,) containing the **log10** of the fraction of infected, beta, and gamma\n        \"\"\"\n        params = soft_minimum(params, torch.tensor(0.0, device=params.device), 2)\n        params = 10**params\n        # set initial fraction of infected\n        initial_infected = params[0]\n        n_agents = self.graph.num_nodes\n        # sample the initial infected nodes\n        probs = initial_infected * torch.ones(n_agents, device=params.device)\n        new_infected = self.sample_bernoulli_gs(probs)\n        # set the initial state\n        infected = new_infected\n        susceptible = 1 - new_infected\n        recovered = torch.zeros(n_agents, device=params.device)\n        x = torch.vstack((infected, susceptible, recovered))\n        return x.reshape(1, 3, n_agents)\n\n    def step(self, params: torch.Tensor, x: torch.Tensor):\n\"\"\"\n        Runs the model forward for one timestep.\n\n        **Arguments**:\n\n        - params: a tensor of shape (3,) containing the **log10** of the fraction of infected, beta, and gamma\n        - x: a tensor of shape (3, n_agents) containing the infected, susceptible, and recovered counts.\n        \"\"\"\n        params = soft_minimum(params, torch.tensor(0.0, device=params.device), 2)\n        params = 10**params\n        _, beta, gamma = params\n        infected, susceptible, recovered = x[-1]\n        # Get number of infected neighbors per node, return 0 if node is not susceptible.\n        n_infected_neighbors = self.mp(self.graph.edge_index, infected, susceptible)\n        # each contact has a beta chance of infecting a susceptible node\n        n_infected_neighbors = torch.clip(n_infected_neighbors, min=0.0, max=5.0)\n        prob_infection = 1 - (1 - beta) ** n_infected_neighbors\n        prob_infection = torch.clip(prob_infection, min=1e-10, max=1.0)\n        # sample the infected nodes\n        new_infected = self.sample_bernoulli_gs(prob_infection)\n        # sample recoverd people\n        prob_recovery = gamma * infected\n        prob_recovery = torch.clip(prob_recovery, min=1e-10, max=1.0)\n        new_recovered = self.sample_bernoulli_gs(prob_recovery)\n        # update the state of the agents\n        infected = infected + new_infected - new_recovered\n        susceptible = susceptible - new_infected\n        recovered = recovered + new_recovered\n        x = torch.vstack((infected, susceptible, recovered)).reshape(1, 3, -1)\n        return x\n\n    def observe(self, x: torch.Tensor):\n\"\"\"\n        Returns the total number of infected and recovered agents per time-step\n\n        **Arguments**:\n\n        - x: a tensor of shape (3, n_agents) containing the infected, susceptible, and recovered counts.\n        \"\"\"\n        return [x[:, 0, :].sum(1), x[:, 2, :].sum(1)]\n</code></pre>"},{"location":"api/models/sir/#blackbirds.models.sir.SIR.__init__","title":"<code>__init__(graph, n_timesteps, device='cpu')</code>","text":"<p>Implements a differentiable SIR model on a graph.</p> <p>Arguments:</p> <ul> <li><code>graph</code>: a networkx graph</li> <li><code>n_timesteps</code>: the number of timesteps to run the model for</li> <li><code>device</code> : device to use (eg. \"cpu\" or \"cuda:0\")</li> </ul> Source code in <code>blackbirds/models/sir.py</code> <pre><code>def __init__(self, graph: networkx.Graph, n_timesteps: int, device: str = \"cpu\"):\n\"\"\"\n    Implements a differentiable SIR model on a graph.\n\n    **Arguments:**\n\n    - `graph`: a networkx graph\n    - `n_timesteps`: the number of timesteps to run the model for\n    - `device` : device to use (eg. \"cpu\" or \"cuda:0\")\n    \"\"\"\n    super().__init__()\n    self.n_timesteps = n_timesteps\n    # convert graph from networkx to pytorch geometric\n    self.graph = torch_geometric.utils.convert.from_networkx(graph).to(device)\n    self.mp = SIRMessagePassing(aggr=\"add\", node_dim=-1)\n</code></pre>"},{"location":"api/models/sir/#blackbirds.models.sir.SIR.initialize","title":"<code>initialize(params)</code>","text":"<p>Initializes the model setting the adequate number of initial infections.</p> <p>Arguments:</p> <ul> <li>params: a tensor of shape (3,) containing the log10 of the fraction of infected, beta, and gamma</li> </ul> Source code in <code>blackbirds/models/sir.py</code> <pre><code>def initialize(self, params: torch.Tensor):\n\"\"\"\n    Initializes the model setting the adequate number of initial infections.\n\n    **Arguments**:\n\n    - params: a tensor of shape (3,) containing the **log10** of the fraction of infected, beta, and gamma\n    \"\"\"\n    params = soft_minimum(params, torch.tensor(0.0, device=params.device), 2)\n    params = 10**params\n    # set initial fraction of infected\n    initial_infected = params[0]\n    n_agents = self.graph.num_nodes\n    # sample the initial infected nodes\n    probs = initial_infected * torch.ones(n_agents, device=params.device)\n    new_infected = self.sample_bernoulli_gs(probs)\n    # set the initial state\n    infected = new_infected\n    susceptible = 1 - new_infected\n    recovered = torch.zeros(n_agents, device=params.device)\n    x = torch.vstack((infected, susceptible, recovered))\n    return x.reshape(1, 3, n_agents)\n</code></pre>"},{"location":"api/models/sir/#blackbirds.models.sir.SIR.observe","title":"<code>observe(x)</code>","text":"<p>Returns the total number of infected and recovered agents per time-step</p> <p>Arguments:</p> <ul> <li>x: a tensor of shape (3, n_agents) containing the infected, susceptible, and recovered counts.</li> </ul> Source code in <code>blackbirds/models/sir.py</code> <pre><code>def observe(self, x: torch.Tensor):\n\"\"\"\n    Returns the total number of infected and recovered agents per time-step\n\n    **Arguments**:\n\n    - x: a tensor of shape (3, n_agents) containing the infected, susceptible, and recovered counts.\n    \"\"\"\n    return [x[:, 0, :].sum(1), x[:, 2, :].sum(1)]\n</code></pre>"},{"location":"api/models/sir/#blackbirds.models.sir.SIR.sample_bernoulli_gs","title":"<code>sample_bernoulli_gs(probs, tau=0.1)</code>","text":"<p>Samples from a Bernoulli distribution in a diferentiable way using Gumble-Softmax</p> <p>Arguments:</p> <ul> <li>probs: a tensor of shape (n,) containing the probabilities of success for each trial</li> <li>tau: the temperature of the Gumble-Softmax distribution</li> </ul> Source code in <code>blackbirds/models/sir.py</code> <pre><code>def sample_bernoulli_gs(self, probs: torch.Tensor, tau: float = 0.1):\n\"\"\"\n    Samples from a Bernoulli distribution in a diferentiable way using Gumble-Softmax\n\n    **Arguments:**\n\n    - probs: a tensor of shape (n,) containing the probabilities of success for each trial\n    - tau: the temperature of the Gumble-Softmax distribution\n    \"\"\"\n    logits = torch.vstack((probs, 1 - probs)).T.log()\n    gs_samples = torch.nn.functional.gumbel_softmax(logits, tau=tau, hard=True)\n    return gs_samples[:, 0]\n</code></pre>"},{"location":"api/models/sir/#blackbirds.models.sir.SIR.step","title":"<code>step(params, x)</code>","text":"<p>Runs the model forward for one timestep.</p> <p>Arguments:</p> <ul> <li>params: a tensor of shape (3,) containing the log10 of the fraction of infected, beta, and gamma</li> <li>x: a tensor of shape (3, n_agents) containing the infected, susceptible, and recovered counts.</li> </ul> Source code in <code>blackbirds/models/sir.py</code> <pre><code>def step(self, params: torch.Tensor, x: torch.Tensor):\n\"\"\"\n    Runs the model forward for one timestep.\n\n    **Arguments**:\n\n    - params: a tensor of shape (3,) containing the **log10** of the fraction of infected, beta, and gamma\n    - x: a tensor of shape (3, n_agents) containing the infected, susceptible, and recovered counts.\n    \"\"\"\n    params = soft_minimum(params, torch.tensor(0.0, device=params.device), 2)\n    params = 10**params\n    _, beta, gamma = params\n    infected, susceptible, recovered = x[-1]\n    # Get number of infected neighbors per node, return 0 if node is not susceptible.\n    n_infected_neighbors = self.mp(self.graph.edge_index, infected, susceptible)\n    # each contact has a beta chance of infecting a susceptible node\n    n_infected_neighbors = torch.clip(n_infected_neighbors, min=0.0, max=5.0)\n    prob_infection = 1 - (1 - beta) ** n_infected_neighbors\n    prob_infection = torch.clip(prob_infection, min=1e-10, max=1.0)\n    # sample the infected nodes\n    new_infected = self.sample_bernoulli_gs(prob_infection)\n    # sample recoverd people\n    prob_recovery = gamma * infected\n    prob_recovery = torch.clip(prob_recovery, min=1e-10, max=1.0)\n    new_recovered = self.sample_bernoulli_gs(prob_recovery)\n    # update the state of the agents\n    infected = infected + new_infected - new_recovered\n    susceptible = susceptible - new_infected\n    recovered = recovered + new_recovered\n    x = torch.vstack((infected, susceptible, recovered)).reshape(1, 3, -1)\n    return x\n</code></pre>"},{"location":"api/models/sir/#blackbirds.models.sir.SIRMessagePassing","title":"<code>SIRMessagePassing</code>","text":"<p>             Bases: <code>MessagePassing</code></p> <p>Class used to pass messages between agents about their infected status.</p> Source code in <code>blackbirds/models/sir.py</code> <pre><code>class SIRMessagePassing(torch_geometric.nn.conv.MessagePassing):\n\"\"\"\n    Class used to pass messages between agents about their infected status.\n    \"\"\"\n\n    def forward(\n        self,\n        edge_index: torch.Tensor,\n        infected: torch.Tensor,\n        susceptible: torch.Tensor,\n    ):\n\"\"\"\n        Computes the sum of the product between the node's susceptibility and the neighbors' infected status.\n\n        **Arguments**:\n\n        - edge_index: a tensor of shape (2, n_edges) containing the edge indices\n        - infected: a tensor of shape (n_nodes,) containing the infected status of each node\n        - susceptible: a tensor of shape (n_nodes,) containing the susceptible status of each node\n        \"\"\"\n        return self.propagate(edge_index, x=infected, y=susceptible)\n\n    def message(self, x_j, y_i):\n        return x_j * y_i\n</code></pre>"},{"location":"api/models/sir/#blackbirds.models.sir.SIRMessagePassing.forward","title":"<code>forward(edge_index, infected, susceptible)</code>","text":"<p>Computes the sum of the product between the node's susceptibility and the neighbors' infected status.</p> <p>Arguments:</p> <ul> <li>edge_index: a tensor of shape (2, n_edges) containing the edge indices</li> <li>infected: a tensor of shape (n_nodes,) containing the infected status of each node</li> <li>susceptible: a tensor of shape (n_nodes,) containing the susceptible status of each node</li> </ul> Source code in <code>blackbirds/models/sir.py</code> <pre><code>def forward(\n    self,\n    edge_index: torch.Tensor,\n    infected: torch.Tensor,\n    susceptible: torch.Tensor,\n):\n\"\"\"\n    Computes the sum of the product between the node's susceptibility and the neighbors' infected status.\n\n    **Arguments**:\n\n    - edge_index: a tensor of shape (2, n_edges) containing the edge indices\n    - infected: a tensor of shape (n_nodes,) containing the infected status of each node\n    - susceptible: a tensor of shape (n_nodes,) containing the susceptible status of each node\n    \"\"\"\n    return self.propagate(edge_index, x=infected, y=susceptible)\n</code></pre>"},{"location":"examples/","title":"Examples","text":"<p>Here we include multiple examples showcasing the utility of Blackbirds to perform calibration in a variety of ways, including variational inference (VI), MCMC, and simulated minimum distance (SMD).</p>"},{"location":"examples/#1-models","title":"1. Models","text":""},{"location":"examples/#11-random-walk","title":"1.1 Random walk","text":"<p>The random walk process we considered is given by </p> \\[ x(t+1) = x(t) + 2\\epsilon -1,  \\epsilon \\sim \\mathrm{Bernoulli}(p) \\] <p>and the inference exercise consists on inferring the value of \\(p\\) from an observed time-series \\(\\{x(t)\\}_t\\). In <code>smd/01-random_walk.ipynb</code> we recover \\(p\\) by just employing gradient descent to minimize the L2 distance between the simulated and the observed time-series. A Bayesian approach using generalized variational inference (GVI) is shown in <code>variational_inference/01-random_walk.ipynb</code>. In this case we consider the candidate family to approximate the generalised posterior as a family of normal distributions where we vary the mean \\(\\mu\\) and standard deviation \\(\\sigma\\).</p>"},{"location":"examples/#12-sir-model","title":"1.2 SIR model","text":"<p>In <code>variational_inference/02-SIR.ipynb</code> we perform GVI on a typical agent-based SIR model. We assume that an infectious disease is spreaded among a population by direct contact between agents. The contacts of the agents are given by a contact graph, which can be any graph generated by <code>networkx</code>. For each contact with an infected agent, the receving agent has a probability \\(\\beta\\) of becoming infected. Thus, at each time-step, the probability of agent \\(i\\) becoming infected is</p> \\[ p_i = 1 - (1-\\beta)^{n_i}, \\] <p>where \\(n_i\\) is the number of infected neighbours. Each infected agent can then recover with probability \\(\\gamma\\). Note that this parameterization of the SIR model does not recover the standard ODE approach for the case of a complete graph. Contrary to the random walk model, we here consider \\(\\mathcal Q\\), the family of approximating distributions to the generalised posterior, to be a normalising flow. As before, we specify a metric to compute the distance between an observed and simulated time-series and perform GVI to recover the model parameters: \\(\\beta\\), \\(\\gamma\\), and the initial fraction of infected agents.</p>"},{"location":"examples/#13-brock-hommes-model","title":"1.3 Brock &amp; Hommes Model","text":"<p>The Brock &amp; Hommes (BH) model is an ABM model of asset pricing with heterogenous agents that despite its simplicity is able to generate quite chaotic dynamics, making it a good test case for the robustness of the methods we implement in this package. We refer to this paper for a more detailed explanation of the model, as well as technical experiments run with <code>BlackBIRDS</code>. In <code>variational_inference/03-brock-hommes.ipynb</code> we show an example of GVI inferring 4 parameters of the BH model.</p>"},{"location":"examples/#2-multi-gpu-parallelisation-support","title":"2. Multi-GPU parallelisation support","text":"<p><code>BlackBIRDS</code> supports multi-CPU and multi-GPU utilization to perform GVI. At each epoch, one needs to sample \\(n\\) samples from the candidate posterior and evaluate the samples using the loss function. This process is embarassingly parallel so we can exploit a large availability of resources. We use <code>MPI4PY</code> to attain this. The example showcased in the documentation should be illustrative enough.</p>"},{"location":"examples/#3-score-based-vs-pathwise-gradients","title":"3. Score-based vs pathwise gradients","text":"<p>To perform GVI, we need to compute the gradient of the expected loss respect to the candidate posterior parameters (see this paper for a good review of Monte Carlo gradient estimation). This gradient can be obtained through the score-based function, which only necessitates gradients of the density but makes no assumptions on the simulator, or through the pathwise gradient, which requires the simulator to be differentiable.</p> <p>While GVI can be conducted without having a differentiable simulator, the pathwise gradient typically shows a lower variance and more efficient training than the score-based approach, making it worthwile to port simulators to differentiable frameworks. A comparison of both methods is shown in <code>examples/variational_inference/04-score_vs_pathwise_gradient.ipynb</code>.</p>"},{"location":"examples/gpu_parallelization/","title":"GPU parallelization","text":"<p>This shows an example on how to run Variational Inference (VI) using multiple GPUs to sample from the model in parallel. We will use the SIR model as an example (see the SIR examples in the VI section).</p> <p>The full example script can be found in <code>examples/variational_inference/05-gpu_parallelisation.py</code>.</p> <p>To achieve multi-gpu parallelization, we use MPI4PY to launch multiple python processes. The main process (rank 0) is in charge of sampling the parameters that need to be evaluated and updating the candidate posterior parameters. The worker processes only job is to receive the parameters from the main process and to evaluate the model on them.</p> <p>Each process needs to allocate the model in the desired GPU. As you may have already seen from the examples section, all the example models accept a <code>device</code> argument that lets us specify the device in the usual torch syntax. So, we initialize the model and the flow in the device we want:</p> <pre><code>def make_model(n_agents, n_timesteps, device):\n    graph = networkx.watts_strogatz_graph(n_agents, 10, 0.1)\n    return SIR(graph=graph, n_timesteps=n_timesteps, device=device)\n\n\ndef make_flow(device):\n    # Define flows\n    torch.manual_seed(0)\n    K = 4\n    latent_size = 3\n    hidden_units = 64\n    hidden_layers = 2\n\n    flows = []\n    for _ in range(K):\n        flows += [\n            nf.flows.AutoregressiveRationalQuadraticSpline(\n                latent_size, hidden_layers, hidden_units\n            )\n        ]\n        flows += [nf.flows.LULinearPermute(latent_size)]\n\n    # Set prior and q0\n    q0 = nf.distributions.DiagGaussian(3, trainable=False)\n\n    # Construct flow model\n    flow = nf.NormalizingFlow(q0=q0, flows=flows)\n    return flow.to(device)\n</code></pre> <p>The loss callable that VI takes can be written as</p> <pre><code>class L2Loss:\n    def __init__(self, model):\n        self.model = model\n        self.loss_fn = torch.nn.MSELoss()\n\n    def __call__(self, params, data):\n        observed_outputs = simulate_and_observe_model(\n            self.model, params, gradient_horizon=0\n        )\n        return self.loss_fn(observed_outputs[0], data[0])\n</code></pre> <p>and we can just setup the training like this</p> <pre><code>def train_flow(flow, model, true_data, n_epochs, n_samples_per_epoch, device):\n    torch.manual_seed(0)\n    # Define a prior\n    prior = torch.distributions.MultivariateNormal(\n        -2.0 * torch.ones(3, device=device), torch.eye(3, device=device)\n    )\n\n    optimizer = torch.optim.AdamW(flow.parameters(), lr=1e-3)\n\n    # We set the regularisation weight to 10.\n    w = 100\n\n    loss = L2Loss(model)\n    # Note that we can track the progress of the training by using tensorboard.\n    # tensorboard --logdir=runs\n    vi = VI(\n        loss=loss,\n        posterior_estimator=flow,\n        prior=prior,\n        optimizer=optimizer,\n        w=w,\n        n_samples_per_epoch=n_samples_per_epoch,\n        device=device,\n    )\n\n    # and we run for 500 epochs without early stopping.\n    vi.run(true_data, n_epochs=n_epochs, max_epochs_without_improvement=np.inf)\n</code></pre> <p>Now the script needs to be set so that each core runs on a different device. One way to achieve is to pass the available devices through cli arguments:</p> <pre><code>if __name__ == \"__main__\":\n    import argparse\n\n    from blackbirds.mpi_setup import mpi_rank\n\n    # parse arguments from cli\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--n_epochs\", type=int, default=500)\n    parser.add_argument(\"--n_agents\", type=int, default=5000)\n    parser.add_argument(\"--n_timesteps\", type=int, default=100)\n    parser.add_argument(\"--n_samples_per_epoch\", type=int, default=5)\n    parser.add_argument(\"--device_ids\", default=[\"cpu\"], nargs=\"+\")\n    args = parser.parse_args()\n\n    # device of this rank\n    device = args.device_ids[mpi_rank]\n\n    model = make_model(args.n_agents, args.n_timesteps, device)\n    true_parameters = torch.tensor(\n        [0.05, 0.05, 0.05], device=device\n    ).log10()  # SIR takes log parameters\n    true_data = model.run_and_observe(true_parameters)\n    flow = make_flow(device)\n    train_flow(\n        flow, model, true_data, args.n_epochs, args.n_samples_per_epoch, device=device\n    )\n</code></pre> <p>So we can just run the script by doing</p> <pre><code>mpirun -np 5 python examples/variational_inference/05-gpu_parallelisation.py --device_ids cuda:0 cuda:1 cuda:2 cuda:3 cuda:4 --n_samples_per_epoch 20\n</code></pre> <p>In this case, we will use 5 GPUs, indexed by the ids we pass. Each GPU will execute 4 evaluations of the model for a total of 20. We can plot the scaling with number of GPUs for this particular model:</p> <p></p> <p>The GPUs used are 8x Tesla V100 32GB.</p>"},{"location":"examples/mcmc/01-mala-mcmc_conjugate_prior_likelihood_pairs/","title":"MALA MCMC on conjugate prior-likelihood pairs","text":"In\u00a0[1]: Copied! <pre>import matplotlib.pyplot as plt\nimport numpy as np\nimport scipy.stats as scistats\nimport torch\nimport torch.distributions\n\nfrom blackbirds.infer import mcmc\n</pre> import matplotlib.pyplot as plt import numpy as np import scipy.stats as scistats import torch import torch.distributions  from blackbirds.infer import mcmc In\u00a0[2]: Copied! <pre>mu_0, sigma_0 = 1., 2.\nprior = torch.distributions.normal.Normal(mu_0, sigma_0)\n</pre> mu_0, sigma_0 = 1., 2. prior = torch.distributions.normal.Normal(mu_0, sigma_0) In\u00a0[3]: Copied! <pre>sigma = 1.\n\ndef negative_log_likelihood(theta, data):\n    dist = torch.distributions.normal.Normal(theta, sigma)\n    return - dist.log_prob(data).sum()\n</pre> sigma = 1.  def negative_log_likelihood(theta, data):     dist = torch.distributions.normal.Normal(theta, sigma)     return - dist.log_prob(data).sum() In\u00a0[4]: Copied! <pre>data_size = 3\ndata = torch.distributions.normal.Normal(-1., sigma).sample((data_size,))\n</pre> data_size = 3 data = torch.distributions.normal.Normal(-1., sigma).sample((data_size,)) In\u00a0[5]: Copied! <pre>data\n</pre> data Out[5]: <pre>tensor([-1.5064, -0.6129,  0.4516])</pre> In\u00a0[6]: Copied! <pre>mala = mcmc.MALA(prior, negative_log_likelihood, w=1.)\n</pre> mala = mcmc.MALA(prior, negative_log_likelihood, w=1.) In\u00a0[7]: Copied! <pre>sampler = mcmc.MCMC(mala, 10_000)\n</pre> sampler = mcmc.MCMC(mala, 10_000) In\u00a0[8]: Copied! <pre>trial_samples = sampler.run(torch.tensor([-.5]), data)\n</pre> trial_samples = sampler.run(torch.tensor([-.5]), data) <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10000/10000 [00:17&lt;00:00, 574.66it/s, Acceptance rate=0.288]\n</pre> In\u00a0[9]: Copied! <pre>thinned_trial_samples = torch.stack(trial_samples)[::100].T\nscale = torch.cov(thinned_trial_samples)\n</pre> thinned_trial_samples = torch.stack(trial_samples)[::100].T scale = torch.cov(thinned_trial_samples) In\u00a0[10]: Copied! <pre>mala = mcmc.MALA(prior, negative_log_likelihood, 1.)\nsampler = mcmc.MCMC(mala, 20_000)\npost_samples = sampler.run(torch.tensor([thinned_trial_samples.mean()]), data, scale=scale)\n</pre> mala = mcmc.MALA(prior, negative_log_likelihood, 1.) sampler = mcmc.MCMC(mala, 20_000) post_samples = sampler.run(torch.tensor([thinned_trial_samples.mean()]), data, scale=scale) <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 20000/20000 [00:35&lt;00:00, 571.00it/s, Acceptance rate=0.759]\n</pre> In\u00a0[11]: Copied! <pre>plt.hist(torch.stack(post_samples).T.numpy()[0, ::100], density=True)\nx = np.linspace(-2, 3., 1000)\nplt.plot(x, scistats.norm.pdf(x, \n                              (mu_0/sigma_0**2 + data.sum()/sigma**2)/(1/sigma_0**2 + data_size/sigma**2),\n                              1/np.sqrt((1/sigma_0**2 + data_size/sigma**2))))\n</pre> plt.hist(torch.stack(post_samples).T.numpy()[0, ::100], density=True) x = np.linspace(-2, 3., 1000) plt.plot(x, scistats.norm.pdf(x,                                (mu_0/sigma_0**2 + data.sum()/sigma**2)/(1/sigma_0**2 + data_size/sigma**2),                               1/np.sqrt((1/sigma_0**2 + data_size/sigma**2)))) Out[11]: <pre>[&lt;matplotlib.lines.Line2D at 0x7f80a8c14640&gt;]</pre> In\u00a0[12]: Copied! <pre>mu_0, sigma_0 = torch.tensor([2., 0.]), torch.tensor([[2., 0.,], [0., 1.]])\nprior = torch.distributions.multivariate_normal.MultivariateNormal(mu_0, sigma_0)\n</pre> mu_0, sigma_0 = torch.tensor([2., 0.]), torch.tensor([[2., 0.,], [0., 1.]]) prior = torch.distributions.multivariate_normal.MultivariateNormal(mu_0, sigma_0) In\u00a0[13]: Copied! <pre>prior_samples = prior.sample((1000,))\nplt.scatter(prior_samples[:,0], prior_samples[:, 1], alpha=0.5)\nplt.ylim([-4,4])\nplt.xlim([-2,6])\n</pre> prior_samples = prior.sample((1000,)) plt.scatter(prior_samples[:,0], prior_samples[:, 1], alpha=0.5) plt.ylim([-4,4]) plt.xlim([-2,6]) Out[13]: <pre>(-2.0, 6.0)</pre> In\u00a0[14]: Copied! <pre>sigma = torch.tensor([[1., 0.4,], [0.4, 2.]])\n\ndef negative_log_likelihood(data, theta):\n    dist = torch.distributions.multivariate_normal.MultivariateNormal(theta, sigma)\n    return - dist.log_prob(data).sum()\n</pre> sigma = torch.tensor([[1., 0.4,], [0.4, 2.]])  def negative_log_likelihood(data, theta):     dist = torch.distributions.multivariate_normal.MultivariateNormal(theta, sigma)     return - dist.log_prob(data).sum() In\u00a0[15]: Copied! <pre>data_size = 3\ntrue_mean = torch.tensor([-1., 2.])\ntrue_density = torch.distributions.multivariate_normal.MultivariateNormal(true_mean, sigma)\ndata = true_density.sample((data_size,))\n</pre> data_size = 3 true_mean = torch.tensor([-1., 2.]) true_density = torch.distributions.multivariate_normal.MultivariateNormal(true_mean, sigma) data = true_density.sample((data_size,)) In\u00a0[16]: Copied! <pre>true_density_samples = true_density.sample((1000,))\nplt.scatter(true_density_samples[:,0], true_density_samples[:,1], alpha=0.5)\n</pre> true_density_samples = true_density.sample((1000,)) plt.scatter(true_density_samples[:,0], true_density_samples[:,1], alpha=0.5) Out[16]: <pre>&lt;matplotlib.collections.PathCollection at 0x7f80a819af50&gt;</pre> In\u00a0[17]: Copied! <pre>data\n</pre> data Out[17]: <pre>tensor([[-1.7573,  0.1746],\n        [-1.2320,  4.3385],\n        [-2.6572,  0.2604]])</pre> In\u00a0[18]: Copied! <pre>mala = mcmc.MALA(prior, negative_log_likelihood, w=1.)\n</pre> mala = mcmc.MALA(prior, negative_log_likelihood, w=1.) In\u00a0[19]: Copied! <pre>sampler = mcmc.MCMC(mala, 20_000)\n</pre> sampler = mcmc.MCMC(mala, 20_000) In\u00a0[20]: Copied! <pre>trial_samples = sampler.run(torch.tensor([-2., -.5]), data)\n</pre> trial_samples = sampler.run(torch.tensor([-2., -.5]), data) <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 20000/20000 [00:45&lt;00:00, 434.89it/s, Acceptance rate=0.106]\n</pre> In\u00a0[21]: Copied! <pre>thinned_trial_samples = torch.stack(trial_samples)[::100].T\ncov = torch.cov(thinned_trial_samples)\n</pre> thinned_trial_samples = torch.stack(trial_samples)[::100].T cov = torch.cov(thinned_trial_samples) In\u00a0[22]: Copied! <pre>init_state = thinned_trial_samples.mean(dim=1)\n</pre> init_state = thinned_trial_samples.mean(dim=1) In\u00a0[23]: Copied! <pre>mala = mcmc.MALA(prior, negative_log_likelihood, 1.)\nsampler = mcmc.MCMC(mala, 20_000)\npost_samples = sampler.run(init_state, data, covariance=cov)\n</pre> mala = mcmc.MALA(prior, negative_log_likelihood, 1.) sampler = mcmc.MCMC(mala, 20_000) post_samples = sampler.run(init_state, data, covariance=cov) <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 20000/20000 [00:44&lt;00:00, 450.00it/s, Acceptance rate=0.642]\n</pre> In\u00a0[24]: Copied! <pre>inv_sigma_0 = torch.inverse(sigma_0)\ninv_sigma = torch.inverse(sigma)\ninv_additions = torch.inverse(inv_sigma_0 + data_size*inv_sigma)\ntrue_mean = torch.matmul(inv_additions, \n                         (torch.matmul(inv_sigma_0, mu_0) + data_size*torch.matmul(inv_sigma, data.mean(dim=0))))\ntrue_cov = torch.inverse(inv_sigma_0 + data_size*inv_sigma)\ntrue_post = torch.distributions.multivariate_normal.MultivariateNormal(true_mean, true_cov)\ntrue_post_samples = true_post.sample((1000,))\n</pre> inv_sigma_0 = torch.inverse(sigma_0) inv_sigma = torch.inverse(sigma) inv_additions = torch.inverse(inv_sigma_0 + data_size*inv_sigma) true_mean = torch.matmul(inv_additions,                           (torch.matmul(inv_sigma_0, mu_0) + data_size*torch.matmul(inv_sigma, data.mean(dim=0)))) true_cov = torch.inverse(inv_sigma_0 + data_size*inv_sigma) true_post = torch.distributions.multivariate_normal.MultivariateNormal(true_mean, true_cov) true_post_samples = true_post.sample((1000,)) In\u00a0[25]: Copied! <pre>post_samples_numpy = torch.stack(post_samples).T.numpy()\nplt.scatter(post_samples_numpy[0, ::100], post_samples_numpy[1, ::100], alpha=0.5, c='b')\nplt.scatter(true_post_samples[:, 0], true_post_samples[:, 1], alpha=0.5, c='r', marker='x')\n</pre> post_samples_numpy = torch.stack(post_samples).T.numpy() plt.scatter(post_samples_numpy[0, ::100], post_samples_numpy[1, ::100], alpha=0.5, c='b') plt.scatter(true_post_samples[:, 0], true_post_samples[:, 1], alpha=0.5, c='r', marker='x') Out[25]: <pre>&lt;matplotlib.collections.PathCollection at 0x7f80a81e5930&gt;</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"examples/mcmc/01-mala-mcmc_conjugate_prior_likelihood_pairs/#mala-mcmc-on-conjugate-prior-likelihood-pairs","title":"MALA MCMC on conjugate prior-likelihood pairs\u00b6","text":""},{"location":"examples/mcmc/01-mala-mcmc_conjugate_prior_likelihood_pairs/#conjugate-normal","title":"Conjugate Normal\u00b6","text":""},{"location":"examples/mcmc/01-mala-mcmc_conjugate_prior_likelihood_pairs/#sampling","title":"Sampling\u00b6","text":""},{"location":"examples/mcmc/01-mala-mcmc_conjugate_prior_likelihood_pairs/#conjugate-multivariate-normal","title":"Conjugate multivariate Normal\u00b6","text":""},{"location":"examples/mcmc/01-mala-mcmc_conjugate_prior_likelihood_pairs/#sampling","title":"Sampling\u00b6","text":""},{"location":"examples/smd/01-random_walk/","title":"Simulated Minimum Distance","text":"<p>In this notebook we illustrate the interface to do point-wise estimates of parameters.</p> <p>We will use the RandomWalk model as an example. In this model, at each step, the agent can take a forward or a backward step. The probability to do the former is given by <code>p</code>.</p> In\u00a0[1]: Copied! <pre>import torch\nimport matplotlib.pyplot as plt\n\nfrom blackbirds.models.random_walk import RandomWalk\n</pre> import torch import matplotlib.pyplot as plt  from blackbirds.models.random_walk import RandomWalk In\u00a0[2]: Copied! <pre>rw = RandomWalk(n_timesteps=100)\n# the random walk takes as input the logit of the parameter\np = 0.25\nlogit_p = torch.logit(torch.tensor([p]))\ntrue_data = rw.run_and_observe(logit_p)\n\nplt.plot(true_data[0])\n</pre> rw = RandomWalk(n_timesteps=100) # the random walk takes as input the logit of the parameter p = 0.25 logit_p = torch.logit(torch.tensor([p])) true_data = rw.run_and_observe(logit_p)  plt.plot(true_data[0]) Out[2]: <pre>[&lt;matplotlib.lines.Line2D at 0x14acb7340&gt;]</pre> <p>We now try to recover the true parameter by minimizing the L2 distance between the two time series:</p> In\u00a0[3]: Copied! <pre>from blackbirds.smd import SMD\n</pre> from blackbirds.smd import SMD In\u00a0[4]: Copied! <pre>initial_parameter = torch.logit(torch.tensor([0.5]))\ninitial_parameter.requires_grad = True\noptimizer = torch.optim.Adam([initial_parameter], lr=1e-2)\n\nsmd = SMD(rw, loss_fn = torch.nn.MSELoss(), optimizer=optimizer, progress_bar=True)\nsmd.run(true_data, n_epochs=1000, max_epochs_without_improvement=100)\n</pre> initial_parameter = torch.logit(torch.tensor([0.5])) initial_parameter.requires_grad = True optimizer = torch.optim.Adam([initial_parameter], lr=1e-2)  smd = SMD(rw, loss_fn = torch.nn.MSELoss(), optimizer=optimizer, progress_bar=True) smd.run(true_data, n_epochs=1000, max_epochs_without_improvement=100) <pre> 18%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                                                                                                                                                                                      | 179/1000 [00:01&lt;00:07, 105.00it/s, loss=40.4, best loss=4.71, epochs since improv.=100]\n</pre> In\u00a0[5]: Copied! <pre># load best parameters\nbest_parameters = torch.load(\"best_parameters.pt\")\nprint(f\"Best parameters are {torch.sigmoid(best_parameters)}\")\n</pre> # load best parameters best_parameters = torch.load(\"best_parameters.pt\") print(f\"Best parameters are {torch.sigmoid(best_parameters)}\") <pre>Best parameters are tensor([0.3626], grad_fn=&lt;SigmoidBackward0&gt;)\n</pre> In\u00a0[8]: Copied! <pre>fitted_data = rw.run_and_observe(best_parameters)\n</pre> fitted_data = rw.run_and_observe(best_parameters) In\u00a0[9]: Copied! <pre>f, ax = plt.subplots()\nax.plot(true_data[0], color = \"black\", label = \"data\")\nax.plot(fitted_data[0].detach().cpu().numpy(), color = \"C0\", label = \"fit\")\nax.legend()\n</pre> f, ax = plt.subplots() ax.plot(true_data[0], color = \"black\", label = \"data\") ax.plot(fitted_data[0].detach().cpu().numpy(), color = \"C0\", label = \"fit\") ax.legend() Out[9]: <pre>&lt;matplotlib.legend.Legend at 0x14e5a1180&gt;</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"examples/smd/01-random_walk/#simulated-minimum-distance","title":"Simulated Minimum Distance\u00b6","text":""},{"location":"examples/variational_inference/01-random_walk/","title":"Random Walk","text":"<p>Let's suppose we have a random walk process defined by $$ x(t+1) = x(t) + 2 \\varepsilon - 1, \\; \\; \\; \\; \\varepsilon \\sim \\mathrm{Bernoulli}(p) $$ where $p$ is the probability of doing a step forward.</p> <p>In this notebook, we create some synthetic data for a value of $p$ and we try to recover it through inference.</p> In\u00a0[1]: Copied! <pre>from blackbirds.models.random_walk import RandomWalk\nfrom blackbirds.infer.vi import VI\nfrom blackbirds.posterior_estimators import TrainableGaussian\nfrom blackbirds.simulate import simulate_and_observe_model\n\nimport torch\nimport matplotlib.pyplot as plt\nimport pandas as pd\n</pre> from blackbirds.models.random_walk import RandomWalk from blackbirds.infer.vi import VI from blackbirds.posterior_estimators import TrainableGaussian from blackbirds.simulate import simulate_and_observe_model  import torch import matplotlib.pyplot as plt import pandas as pd In\u00a0[2]: Copied! <pre>rw = RandomWalk(n_timesteps=100)\n</pre> rw = RandomWalk(n_timesteps=100) In\u00a0[3]: Copied! <pre>true_p = torch.logit(torch.tensor(0.25))\ntrue_data = rw.observe(rw.run(torch.tensor([true_p])))\n\nplt.plot(true_data[0].numpy())\n</pre> true_p = torch.logit(torch.tensor(0.25)) true_data = rw.observe(rw.run(torch.tensor([true_p])))  plt.plot(true_data[0].numpy()) Out[3]: <pre>[&lt;matplotlib.lines.Line2D at 0x16bed7ca0&gt;]</pre> <p>The loss callable needs to take as input the model parameters and true data and return the loss value.</p> In\u00a0[4]: Copied! <pre>class L2Loss:\n    def __init__(self, model):\n        self.model = model\n        self.loss_fn = torch.nn.MSELoss()\n    def __call__(self, params, data):\n        observed_outputs = simulate_and_observe_model(self.model, params)\n        return self.loss_fn(observed_outputs[0], data[0])\n</pre> class L2Loss:     def __init__(self, model):         self.model = model         self.loss_fn = torch.nn.MSELoss()     def __call__(self, params, data):         observed_outputs = simulate_and_observe_model(self.model, params)         return self.loss_fn(observed_outputs[0], data[0]) In\u00a0[5]: Copied! <pre>posterior_estimator = TrainableGaussian([0.], 1.0)\nprior = torch.distributions.Normal(true_p + 0.2, 1)\noptimizer = torch.optim.Adam(posterior_estimator.parameters(), 1e-2)\nloss = L2Loss(rw)\n\nvi = VI(loss, posterior_estimator=posterior_estimator, prior=prior, optimizer=optimizer, w = 0)\n</pre> posterior_estimator = TrainableGaussian([0.], 1.0) prior = torch.distributions.Normal(true_p + 0.2, 1) optimizer = torch.optim.Adam(posterior_estimator.parameters(), 1e-2) loss = L2Loss(rw)  vi = VI(loss, posterior_estimator=posterior_estimator, prior=prior, optimizer=optimizer, w = 0) In\u00a0[6]: Copied! <pre># we can now train the estimator for a 100 epochs\nvi.run(true_data, 1000, max_epochs_without_improvement=100)\n</pre> # we can now train the estimator for a 100 epochs vi.run(true_data, 1000, max_epochs_without_improvement=100) <pre> 24%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                                                        | 243/1000 [00:47&lt;02:28,  5.09it/s, loss=29.2, reg.=0, total=29.2, best loss=19.8, epochs since improv.=100]\n</pre> <p>The model stops when it hits a certain amount of epochs without improvement. The run function returns the loss per epoch as well as the best model weights. Let's have a look at the loss first:</p> In\u00a0[7]: Copied! <pre>df = pd.DataFrame(vi.losses_hist)\ndf.head()\n</pre> df = pd.DataFrame(vi.losses_hist) df.head() Out[7]: total loss regularisation 0 1800.693115 1800.693115 0.0 1 942.427734 942.427734 0.0 2 1702.843506 1702.843506 0.0 3 2089.033691 2089.033691 0.0 4 2143.318848 2143.318848 0.0 In\u00a0[8]: Copied! <pre>df.plot(y=\"total\", logy=True)\n</pre> df.plot(y=\"total\", logy=True) Out[8]: <pre>&lt;Axes: &gt;</pre> In\u00a0[9]: Copied! <pre># We can now load the best model\nposterior_estimator.load_state_dict(vi.best_estimator_state_dict)\n</pre> # We can now load the best model posterior_estimator.load_state_dict(vi.best_estimator_state_dict) Out[9]: <pre>&lt;All keys matched successfully&gt;</pre> In\u00a0[10]: Copied! <pre># and plot the posterior\nwith torch.no_grad():\n    samples = posterior_estimator.sample(20000)[0].flatten().cpu()\nplt.hist(samples, density=True, bins=100);\nplt.axvline(true_p, label = \"true value\", color = \"black\", linestyle=\":\")\n</pre> # and plot the posterior with torch.no_grad():     samples = posterior_estimator.sample(20000)[0].flatten().cpu() plt.hist(samples, density=True, bins=100); plt.axvline(true_p, label = \"true value\", color = \"black\", linestyle=\":\") Out[10]: <pre>&lt;matplotlib.lines.Line2D at 0x16c004880&gt;</pre> In\u00a0[11]: Copied! <pre># compare the predictions to the synthetic data:\n\nf, ax = plt.subplots()\n\nfor i in range(50):\n    with torch.no_grad():\n        sim_rw = rw.observe(rw.run(posterior_estimator.sample(1)[0]))[0].numpy()\n    ax.plot(sim_rw, color = \"C0\", alpha=0.5)\n    \nax.plot([], [], color = \"C0\", label = \"predicted\")\nax.plot(true_data[0], color = \"black\", linewidth=2, label = \"data\")\n\nax.legend()\n</pre> # compare the predictions to the synthetic data:  f, ax = plt.subplots()  for i in range(50):     with torch.no_grad():         sim_rw = rw.observe(rw.run(posterior_estimator.sample(1)[0]))[0].numpy()     ax.plot(sim_rw, color = \"C0\", alpha=0.5)      ax.plot([], [], color = \"C0\", label = \"predicted\") ax.plot(true_data[0], color = \"black\", linewidth=2, label = \"data\")  ax.legend() Out[11]: <pre>&lt;matplotlib.legend.Legend at 0x16c0515a0&gt;</pre>"},{"location":"examples/variational_inference/01-random_walk/#random-walk","title":"Random Walk\u00b6","text":""},{"location":"examples/variational_inference/01-random_walk/#generating-synthetic-data","title":"Generating synthetic data\u00b6","text":""},{"location":"examples/variational_inference/01-random_walk/#defining-the-loss","title":"Defining the loss\u00b6","text":""},{"location":"examples/variational_inference/02-SIR/","title":"SIR model","text":"<p>Here we calibrate a differentiable version of the SIR model. We use the exact same model as  https://ndlib.readthedocs.io/en/latest/reference/models/epidemics/SIR.html, but implemented in a differentiable way.</p> In\u00a0[1]: Copied! <pre>from blackbirds.models.sir import SIR\nfrom blackbirds.infer.vi import VI\nfrom blackbirds.simulate import simulate_and_observe_model\n\nimport torch\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport networkx\nimport normflows as nf\nimport pygtc\n</pre> from blackbirds.models.sir import SIR from blackbirds.infer.vi import VI from blackbirds.simulate import simulate_and_observe_model  import torch import numpy as np import matplotlib.pyplot as plt import pandas as pd import networkx import normflows as nf import pygtc In\u00a0[2]: Copied! <pre>device = \"cpu\"\n</pre> device = \"cpu\" In\u00a0[3]: Copied! <pre># generate a random graph\nn_agents = 1000\ngraph = networkx.watts_strogatz_graph(n_agents, 10, 0.1)\n</pre> # generate a random graph n_agents = 1000 graph = networkx.watts_strogatz_graph(n_agents, 10, 0.1) In\u00a0[4]: Copied! <pre>sir = SIR(graph, n_timesteps=100, device=device)\n</pre> sir = SIR(graph, n_timesteps=100, device=device) In\u00a0[5]: Copied! <pre>%%time\n# the simulator takes as parameters the log10 of the fraction of initial cases, beta, and gamma parameters\ntrue_parameters = torch.log10(torch.tensor([0.05, 0.05, 0.05], device=device))\ndata = sir.run_and_observe(true_parameters)\ntrue_infected, true_recovered = data\n</pre> %%time # the simulator takes as parameters the log10 of the fraction of initial cases, beta, and gamma parameters true_parameters = torch.log10(torch.tensor([0.05, 0.05, 0.05], device=device)) data = sir.run_and_observe(true_parameters) true_infected, true_recovered = data <pre>CPU times: user 43.5 ms, sys: 19.3 ms, total: 62.8 ms\nWall time: 48 ms\n</pre> In\u00a0[6]: Copied! <pre>f, ax = plt.subplots()\nax.plot(true_infected.cpu(), label = \"active infected\")\nax.set_xlabel(\"Time-step\")\nax.plot(true_recovered.cpu(), label = \"cumulative recovered\")\nax.legend()\n</pre> f, ax = plt.subplots() ax.plot(true_infected.cpu(), label = \"active infected\") ax.set_xlabel(\"Time-step\") ax.plot(true_recovered.cpu(), label = \"cumulative recovered\") ax.legend() Out[6]: <pre>&lt;matplotlib.legend.Legend at 0x2a951e380&gt;</pre> <p>We construct the flow using the normflows library (https://github.com/VincentStimper/normalizing-flows )</p> <p>In this case we define Neural Spline Flow with 4 transformations, each parametrised by 2 layers with 64 hidden units.</p> In\u00a0[7]: Copied! <pre>def make_flow(n_parameters, device):\n    K = 16\n    torch.manual_seed(0)\n    flows = []\n    for i in range(K):\n        flows.append(nf.flows.MaskedAffineAutoregressive(n_parameters, 20, num_blocks=2))\n        flows.append(nf.flows.Permute(n_parameters, mode=\"swap\"))\n    q0 = nf.distributions.DiagGaussian(n_parameters)\n    nfm = nf.NormalizingFlow(q0=q0, flows=flows)\n    return nfm.to(device)\n</pre> def make_flow(n_parameters, device):     K = 16     torch.manual_seed(0)     flows = []     for i in range(K):         flows.append(nf.flows.MaskedAffineAutoregressive(n_parameters, 20, num_blocks=2))         flows.append(nf.flows.Permute(n_parameters, mode=\"swap\"))     q0 = nf.distributions.DiagGaussian(n_parameters)     nfm = nf.NormalizingFlow(q0=q0, flows=flows)     return nfm.to(device) In\u00a0[8]: Copied! <pre># Plot the inital flow:\nflow = make_flow(len(true_parameters), device=device)\nsamples = flow.sample(10000)[0].cpu().detach().numpy()\n\npygtc.plotGTC([samples], truths=true_parameters.cpu().numpy(), figureSize=7, paramNames=[r\"$I_0$\", r\"$\\beta$\", r\"$\\gamma$\"]);\n</pre> # Plot the inital flow: flow = make_flow(len(true_parameters), device=device) samples = flow.sample(10000)[0].cpu().detach().numpy()  pygtc.plotGTC([samples], truths=true_parameters.cpu().numpy(), figureSize=7, paramNames=[r\"$I_0$\", r\"$\\beta$\", r\"$\\gamma$\"]); <p>Let's also plot runs sampled from the untrained flow, to compare later with the trained flow.</p> In\u00a0[9]: Copied! <pre>f, ax = plt.subplots()\n\nfor i in range(15):\n    with torch.no_grad():\n        sim_sir = sir.run_and_observe(flow.sample(1)[0][0])\n    ax.plot(sim_sir[0].cpu().numpy(), color = \"C0\", alpha=0.5)\n    ax.plot(sim_sir[1].cpu().numpy(), color = \"C1\", alpha=0.5)\n    \nax.plot([], [], color = \"C0\", label = \"predicted infected\")\nax.plot([], [], color = \"C1\", label = \"predicted recovered\")\nax.plot(data[0].cpu(), color = \"black\", linewidth=2, label = \"data infected\")\nax.plot(data[1].cpu(), color = \"black\", linewidth=2, label = \"data recovered\", linestyle=\"--\")\nax.legend()\n</pre> f, ax = plt.subplots()  for i in range(15):     with torch.no_grad():         sim_sir = sir.run_and_observe(flow.sample(1)[0][0])     ax.plot(sim_sir[0].cpu().numpy(), color = \"C0\", alpha=0.5)     ax.plot(sim_sir[1].cpu().numpy(), color = \"C1\", alpha=0.5)      ax.plot([], [], color = \"C0\", label = \"predicted infected\") ax.plot([], [], color = \"C1\", label = \"predicted recovered\") ax.plot(data[0].cpu(), color = \"black\", linewidth=2, label = \"data infected\") ax.plot(data[1].cpu(), color = \"black\", linewidth=2, label = \"data recovered\", linestyle=\"--\") ax.legend() Out[9]: <pre>&lt;matplotlib.legend.Legend at 0x2aa81a590&gt;</pre> In\u00a0[10]: Copied! <pre>torch.manual_seed(0)\n\nclass L2Loss:\n    def __init__(self, model):\n        self.model = model\n        self.loss_fn = torch.nn.MSELoss()\n        \n    def __call__(self, params, data):\n        observed_outputs = simulate_and_observe_model(self.model, params, gradient_horizon=0)\n        return self.loss_fn(observed_outputs[0], data[0])\n\nprior = torch.distributions.MultivariateNormal(-2.0 * torch.ones(3, device=device), torch.eye(3, device=device))\nloss = L2Loss(sir)\noptimizer = torch.optim.AdamW(flow.parameters(), lr=1e-3)\nw = 100\n\nvi = VI(loss = loss,\n        posterior_estimator = flow,\n        prior=prior,\n        optimizer=optimizer,\n        w=w,\n        n_samples_per_epoch=10,\n        log_tensorboard=True,\n        device=device\n       )\n\n# and we run for 1000 epochs, stopping if the loss doesn't improve in 100 epochs.\nvi.run(data, n_epochs=1000, max_epochs_without_improvement=50);\n</pre> torch.manual_seed(0)  class L2Loss:     def __init__(self, model):         self.model = model         self.loss_fn = torch.nn.MSELoss()              def __call__(self, params, data):         observed_outputs = simulate_and_observe_model(self.model, params, gradient_horizon=0)         return self.loss_fn(observed_outputs[0], data[0])  prior = torch.distributions.MultivariateNormal(-2.0 * torch.ones(3, device=device), torch.eye(3, device=device)) loss = L2Loss(sir) optimizer = torch.optim.AdamW(flow.parameters(), lr=1e-3) w = 100  vi = VI(loss = loss,         posterior_estimator = flow,         prior=prior,         optimizer=optimizer,         w=w,         n_samples_per_epoch=10,         log_tensorboard=True,         device=device        )  # and we run for 1000 epochs, stopping if the loss doesn't improve in 100 epochs. vi.run(data, n_epochs=1000, max_epochs_without_improvement=50); <pre> 22%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                                                                                                                                      | 223/1000 [07:05&lt;24:44,  1.91s/it, loss=6.05e+3, reg.=561, total=6.61e+3, best loss=2.73e+3, epochs since improv.=50]\n</pre> In\u00a0[11]: Copied! <pre># Let's have a look at the loss over epochs:\n\ndf = pd.DataFrame(vi.losses_hist)\ndf.plot(logy=True)\n</pre> # Let's have a look at the loss over epochs:  df = pd.DataFrame(vi.losses_hist) df.plot(logy=True) Out[11]: <pre>&lt;Axes: &gt;</pre> In\u00a0[12]: Copied! <pre># We can load the best model to check the results\nflow.load_state_dict(vi.best_estimator_state_dict)\n</pre> # We can load the best model to check the results flow.load_state_dict(vi.best_estimator_state_dict) Out[12]: <pre>&lt;All keys matched successfully&gt;</pre> In\u00a0[13]: Copied! <pre># Plot the final flow posterior approximator and compare it to the real parameters:\nsamples = flow.sample(50000)[0].cpu().detach().numpy()\n\n#corner(samples, truths=true_parameters.numpy(), smooth=2, range = ((-2, -1.0), (-1.7, -1.0), (-1.4, -1.25)), labels=[\"initial_fraction_infected\", r\"$\\beta$\", r\"$\\gamma$\"]);\n#corner(samples, truths=true_parameters.numpy(), smooth=2, labels=[\"initial_fraction_infected\", r\"$\\beta$\", r\"$\\gamma$\"]);\npygtc.plotGTC([samples], truths=true_parameters.cpu().numpy(), figureSize=10, priors=[(-2, 1) for i in range(3)], paramRanges=[(-3.0, -0.5) for i in range(3)]);\n</pre> # Plot the final flow posterior approximator and compare it to the real parameters: samples = flow.sample(50000)[0].cpu().detach().numpy()  #corner(samples, truths=true_parameters.numpy(), smooth=2, range = ((-2, -1.0), (-1.7, -1.0), (-1.4, -1.25)), labels=[\"initial_fraction_infected\", r\"$\\beta$\", r\"$\\gamma$\"]); #corner(samples, truths=true_parameters.numpy(), smooth=2, labels=[\"initial_fraction_infected\", r\"$\\beta$\", r\"$\\gamma$\"]); pygtc.plotGTC([samples], truths=true_parameters.cpu().numpy(), figureSize=10, priors=[(-2, 1) for i in range(3)], paramRanges=[(-3.0, -0.5) for i in range(3)]); In\u00a0[14]: Copied! <pre># compare the predictions to the synthetic data:\n\nf, ax = plt.subplots()\n\nfor i in range(25):\n    with torch.no_grad():\n        sim_sir = sir.observe(sir.run((flow.sample(1)[0][0])))\n    ax.plot(sim_sir[0].cpu().numpy(), color = \"C0\", alpha=0.5)\n    ax.plot(sim_sir[1].cpu().numpy(), color = \"C1\", alpha=0.5)\n    \nax.plot([], [], color = \"C0\", label = \"predicted infected\")\nax.plot([], [], color = \"C1\", label = \"predicted recovered\")\nax.plot(data[0].cpu(), color = \"black\", linewidth=2, label = \"data infected\")\nax.plot(data[1].cpu(), color = \"black\", linewidth=2, label = \"data recovered\", linestyle=\"--\")\n\nax.legend()\n</pre> # compare the predictions to the synthetic data:  f, ax = plt.subplots()  for i in range(25):     with torch.no_grad():         sim_sir = sir.observe(sir.run((flow.sample(1)[0][0])))     ax.plot(sim_sir[0].cpu().numpy(), color = \"C0\", alpha=0.5)     ax.plot(sim_sir[1].cpu().numpy(), color = \"C1\", alpha=0.5)      ax.plot([], [], color = \"C0\", label = \"predicted infected\") ax.plot([], [], color = \"C1\", label = \"predicted recovered\") ax.plot(data[0].cpu(), color = \"black\", linewidth=2, label = \"data infected\") ax.plot(data[1].cpu(), color = \"black\", linewidth=2, label = \"data recovered\", linestyle=\"--\")  ax.legend() Out[14]: <pre>&lt;matplotlib.legend.Legend at 0x2aaf95930&gt;</pre>"},{"location":"examples/variational_inference/02-SIR/#sir-model","title":"SIR model\u00b6","text":""},{"location":"examples/variational_inference/02-SIR/#generating-synthetic-true-data","title":"Generating synthetic true data\u00b6","text":""},{"location":"examples/variational_inference/02-SIR/#approximating-the-posterior-by-a-normalizing-flow","title":"Approximating the posterior by a normalizing flow\u00b6","text":""},{"location":"examples/variational_inference/02-SIR/#train-the-flow","title":"Train the flow\u00b6","text":""},{"location":"examples/variational_inference/03-brock_hommes/","title":"Brock and Hommes model","text":"In\u00a0[1]: Copied! <pre>from blackbirds.models.brock_hommes import BrockHommes\nfrom blackbirds.infer import VI\nfrom blackbirds.utils import soft_minimum, soft_maximum\nfrom blackbirds.simulate import simulate_and_observe_model\n\nimport torch\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport networkx\nimport normflows as nf\nimport pygtc\n</pre> from blackbirds.models.brock_hommes import BrockHommes from blackbirds.infer import VI from blackbirds.utils import soft_minimum, soft_maximum from blackbirds.simulate import simulate_and_observe_model  import torch import numpy as np import matplotlib.pyplot as plt import pandas as pd import networkx import normflows as nf import pygtc In\u00a0[2]: Copied! <pre>class MMDLoss:\n    def __init__(self, model, data):\n        self.model = model\n        self.y = data[0]\n        self.y_matrix = self.y.reshape(1,-1,1)\n        self.y_sigma = torch.median(torch.pow(torch.cdist(self.y_matrix, self.y_matrix), 2))\n        ny = self.y.shape[0]\n        self.kyy = (torch.exp( - torch.pow(torch.cdist(self.y_matrix, self.y_matrix), 2) / self.y_sigma ) - torch.eye(ny)).sum() / (ny * (ny - 1))\n        \n    def __call__(self, params, data):\n        x = simulate_and_observe_model(self.model, params, gradient_horizon=0)[0]\n        nx = x.shape[0]\n        x_matrix = x.reshape(1,-1,1)\n        kxx = torch.exp( - torch.pow(torch.cdist(x_matrix, x_matrix), 2) / self.y_sigma )\n        #kxx = torch.nan_to_num(kxx, 0.)\n        kxx = (kxx - torch.eye(nx)).sum() / (nx * (nx - 1))\n        kxy = torch.exp( - torch.pow(torch.cdist(x_matrix, self.y_matrix), 2) / self.y_sigma )\n        #kxy = torch.nan_to_num(kxy, 0.)\n        kxy = kxy.mean()\n        return kxx + self.kyy - 2 * kxy\n</pre> class MMDLoss:     def __init__(self, model, data):         self.model = model         self.y = data[0]         self.y_matrix = self.y.reshape(1,-1,1)         self.y_sigma = torch.median(torch.pow(torch.cdist(self.y_matrix, self.y_matrix), 2))         ny = self.y.shape[0]         self.kyy = (torch.exp( - torch.pow(torch.cdist(self.y_matrix, self.y_matrix), 2) / self.y_sigma ) - torch.eye(ny)).sum() / (ny * (ny - 1))              def __call__(self, params, data):         x = simulate_and_observe_model(self.model, params, gradient_horizon=0)[0]         nx = x.shape[0]         x_matrix = x.reshape(1,-1,1)         kxx = torch.exp( - torch.pow(torch.cdist(x_matrix, x_matrix), 2) / self.y_sigma )         #kxx = torch.nan_to_num(kxx, 0.)         kxx = (kxx - torch.eye(nx)).sum() / (nx * (nx - 1))         kxy = torch.exp( - torch.pow(torch.cdist(x_matrix, self.y_matrix), 2) / self.y_sigma )         #kxy = torch.nan_to_num(kxy, 0.)         kxy = kxy.mean()         return kxx + self.kyy - 2 * kxy <p>Following Dyer et al we fix</p> In\u00a0[3]: Copied! <pre>H = 4\nlog_r = np.log(1.0)\nlog_sigma = np.log(0.04)\ng1, b1, b4, = 0, 0, 0\ng4 = 1.01\nlog_beta = np.log(120)\nn_timesteps = 100\n\nclass CustomBrockHommes(BrockHommes):\n    def step(self, params, x):\n        expanded_params = torch.tensor([log_beta, g1, 0, 0, g4, b1, 0, 0, b4, log_sigma, log_r])\n        expanded_params[2] = params[0] # g2\n        expanded_params[3] = params[1] # g3\n        expanded_params[6] = params[2] # b2\n        expanded_params[7] = params[3] # b2\n        return super().step(expanded_params, x)\n</pre> H = 4 log_r = np.log(1.0) log_sigma = np.log(0.04) g1, b1, b4, = 0, 0, 0 g4 = 1.01 log_beta = np.log(120) n_timesteps = 100  class CustomBrockHommes(BrockHommes):     def step(self, params, x):         expanded_params = torch.tensor([log_beta, g1, 0, 0, g4, b1, 0, 0, b4, log_sigma, log_r])         expanded_params[2] = params[0] # g2         expanded_params[3] = params[1] # g3         expanded_params[6] = params[2] # b2         expanded_params[7] = params[3] # b2         return super().step(expanded_params, x) In\u00a0[4]: Copied! <pre>model = CustomBrockHommes(n_timesteps)\n</pre> model = CustomBrockHommes(n_timesteps) In\u00a0[5]: Copied! <pre>g2 = 0.9\ng3 = 0.9\nb2 = 0.2\nb3 = -0.2\n\ntrue_parameters = torch.tensor([g2, g3, b2, b3])\ntorch.manual_seed(0)\nx = model.run(true_parameters)\ndata = model.observe(x)\n</pre> g2 = 0.9 g3 = 0.9 b2 = 0.2 b3 = -0.2  true_parameters = torch.tensor([g2, g3, b2, b3]) torch.manual_seed(0) x = model.run(true_parameters) data = model.observe(x) In\u00a0[6]: Copied! <pre>plt.plot(data[0].cpu())\n</pre> plt.plot(data[0].cpu()) Out[6]: <pre>[&lt;matplotlib.lines.Line2D at 0x15f687b20&gt;]</pre> In\u00a0[7]: Copied! <pre>def make_flow():\n    torch.manual_seed(0)\n    base = nf.distributions.base.DiagGaussian(len(true_parameters))\n    num_layers = 5\n    latent_size = len(true_parameters)\n    flows = []\n    for i in range(num_layers):\n        param_map = nf.nets.MLP([2, 50, 50, latent_size], init_zeros=True)\n        flows.append(nf.flows.AffineCouplingBlock(param_map))\n        flows.append(nf.flows.Permute(latent_size, mode='swap'))\n    return nf.NormalizingFlow(base, flows)\n</pre> def make_flow():     torch.manual_seed(0)     base = nf.distributions.base.DiagGaussian(len(true_parameters))     num_layers = 5     latent_size = len(true_parameters)     flows = []     for i in range(num_layers):         param_map = nf.nets.MLP([2, 50, 50, latent_size], init_zeros=True)         flows.append(nf.flows.AffineCouplingBlock(param_map))         flows.append(nf.flows.Permute(latent_size, mode='swap'))     return nf.NormalizingFlow(base, flows) In\u00a0[8]: Copied! <pre>torch.manual_seed(0)\nprior = torch.distributions.MultivariateNormal(torch.tensor([0.5, 0.5, 0.5, -0.5]), 1.0 * torch.eye(len(true_parameters)))\nestimator = make_flow()\nloss = MMDLoss(model, data)\noptimizer = torch.optim.AdamW(estimator.parameters(), lr=1e-3)\nvi = VI(loss = loss, \n        posterior_estimator = estimator, \n        prior=prior, \n        optimizer=optimizer, \n        n_samples_per_epoch=10,\n        w=0.001,\n        log_tensorboard=True,\n        gradient_estimation_method=\"pathwise\",\n        gradient_clipping_norm=1.0,\n        gradient_horizon=0\n    )\n\nvi.run(data, n_epochs=1000, max_epochs_without_improvement=50);\n</pre> torch.manual_seed(0) prior = torch.distributions.MultivariateNormal(torch.tensor([0.5, 0.5, 0.5, -0.5]), 1.0 * torch.eye(len(true_parameters))) estimator = make_flow() loss = MMDLoss(model, data) optimizer = torch.optim.AdamW(estimator.parameters(), lr=1e-3) vi = VI(loss = loss,          posterior_estimator = estimator,          prior=prior,          optimizer=optimizer,          n_samples_per_epoch=10,         w=0.001,         log_tensorboard=True,         gradient_estimation_method=\"pathwise\",         gradient_clipping_norm=1.0,         gradient_horizon=0     )  vi.run(data, n_epochs=1000, max_epochs_without_improvement=50); <pre> 35%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                                                                                                                           | 351/1000 [04:24&lt;08:08,  1.33it/s, loss=-.00783, reg.=0.0097, total=0.00187, best loss=-.00936, epochs since improv.=50]\n</pre> In\u00a0[9]: Copied! <pre># We can load the best model to check the results\nestimator.load_state_dict(vi.best_estimator_state_dict)\n</pre> # We can load the best model to check the results estimator.load_state_dict(vi.best_estimator_state_dict) Out[9]: <pre>&lt;All keys matched successfully&gt;</pre> In\u00a0[10]: Copied! <pre># Plot the final flow posterior approximator and compare it to the real parameters:\nsamples = estimator.sample(10000)[0].detach().numpy()\nsamples_prior = prior.sample((10000,)).numpy()\n\npygtc.plotGTC([samples, samples_prior], figureSize=10, truths = true_parameters.numpy(), chainLabels = [\"flow\", \"prior\"]);\n#corner(samples, truths=true_parameters.numpy(), smooth=2);#, range=[(0,1) for i in range(3)]+ [(-1,0)]);\n</pre> # Plot the final flow posterior approximator and compare it to the real parameters: samples = estimator.sample(10000)[0].detach().numpy() samples_prior = prior.sample((10000,)).numpy()  pygtc.plotGTC([samples, samples_prior], figureSize=10, truths = true_parameters.numpy(), chainLabels = [\"flow\", \"prior\"]); #corner(samples, truths=true_parameters.numpy(), smooth=2);#, range=[(0,1) for i in range(3)]+ [(-1,0)]); In\u00a0[11]: Copied! <pre>n_samples = 1\nwith torch.no_grad():\n    flow_samples = estimator.sample((n_samples))[0]\n\nf, ax = plt.subplots(figsize=(20, 3))\nfor i in range(n_samples):\n    prediction = model.observe(model.run(flow_samples[i]))\n    ax.plot(prediction[0].cpu(), color = \"C0\", label = \"predicted\")\n    true = model.observe(model.run(true_parameters))\n    ax.plot(true[0], color = \"black\", label = \"true\")\n\nax.legend()\n</pre> n_samples = 1 with torch.no_grad():     flow_samples = estimator.sample((n_samples))[0]  f, ax = plt.subplots(figsize=(20, 3)) for i in range(n_samples):     prediction = model.observe(model.run(flow_samples[i]))     ax.plot(prediction[0].cpu(), color = \"C0\", label = \"predicted\")     true = model.observe(model.run(true_parameters))     ax.plot(true[0], color = \"black\", label = \"true\")  ax.legend() Out[11]: <pre>&lt;matplotlib.legend.Legend at 0x297e5eef0&gt;</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"examples/variational_inference/03-brock_hommes/#brock-and-hommes-model","title":"Brock and Hommes model\u00b6","text":""},{"location":"examples/variational_inference/04-score_vs_pathwise_gradient/","title":"Score vs Pathwise Gradient","text":"In\u00a0[1]: Copied! <pre>from blackbirds.models.sir import SIR\nfrom blackbirds.infer import VI\nfrom blackbirds.simulate import simulate_and_observe_model\n\nimport torch\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport networkx\nimport pygtc\nimport normflows as nf\n</pre> from blackbirds.models.sir import SIR from blackbirds.infer import VI from blackbirds.simulate import simulate_and_observe_model  import torch import numpy as np import matplotlib.pyplot as plt import pandas as pd import networkx import pygtc import normflows as nf In\u00a0[2]: Copied! <pre>n_agents = 1000\ngraph = networkx.watts_strogatz_graph(n_agents, 10, 0.1)\nsir = SIR(graph, n_timesteps=100)\n</pre> n_agents = 1000 graph = networkx.watts_strogatz_graph(n_agents, 10, 0.1) sir = SIR(graph, n_timesteps=100) In\u00a0[3]: Copied! <pre>true_parameters = torch.tensor([0.05, 0.05, 0.05]).log10()\ndata = sir.observe(sir.run(true_parameters))\n</pre> true_parameters = torch.tensor([0.05, 0.05, 0.05]).log10() data = sir.observe(sir.run(true_parameters)) In\u00a0[4]: Copied! <pre>prior = torch.distributions.MultivariateNormal(-2.0 * torch.ones(3), torch.eye(3))\n</pre> prior = torch.distributions.MultivariateNormal(-2.0 * torch.ones(3), torch.eye(3)) In\u00a0[5]: Copied! <pre>def setup_flow():\n    K = 4\n    torch.manual_seed(0)\n    \n    latent_size = 3\n    hidden_units = 64\n    hidden_layers = 2\n    \n    flows = []\n    for i in range(K):\n        flows += [nf.flows.AutoregressiveRationalQuadraticSpline(latent_size, hidden_layers, hidden_units)]\n        flows += [nf.flows.LULinearPermute(latent_size)]\n    \n    # Set prior and q0\n    q0 = nf.distributions.DiagGaussian(3, trainable=False)\n        \n    # Construct flow model\n    flow = nf.NormalizingFlow(q0=q0, flows=flows)\n    return flow\n\nclass L2Loss:\n    def __init__(self, model):\n        self.model = model\n        self.loss_fn = torch.nn.MSELoss()\n    def __call__(self, params, data):\n        observed_outputs = simulate_and_observe_model(self.model, params, gradient_horizon=0)\n        return self.loss_fn(observed_outputs[0], data[0])\n</pre> def setup_flow():     K = 4     torch.manual_seed(0)          latent_size = 3     hidden_units = 64     hidden_layers = 2          flows = []     for i in range(K):         flows += [nf.flows.AutoregressiveRationalQuadraticSpline(latent_size, hidden_layers, hidden_units)]         flows += [nf.flows.LULinearPermute(latent_size)]          # Set prior and q0     q0 = nf.distributions.DiagGaussian(3, trainable=False)              # Construct flow model     flow = nf.NormalizingFlow(q0=q0, flows=flows)     return flow  class L2Loss:     def __init__(self, model):         self.model = model         self.loss_fn = torch.nn.MSELoss()     def __call__(self, params, data):         observed_outputs = simulate_and_observe_model(self.model, params, gradient_horizon=0)         return self.loss_fn(observed_outputs[0], data[0]) In\u00a0[6]: Copied! <pre>def train_estimator(gradient_estimation_mode, n_samples_per_epoch):\n    torch.manual_seed(0)\n    posterior_estimator = setup_flow() \n    optimizer = torch.optim.Adam(posterior_estimator.parameters(), 1e-3)\n    loss = L2Loss(sir)\n    vi = VI(loss = loss, \n            posterior_estimator=posterior_estimator, \n            prior=prior, \n            optimizer=optimizer,\n            w = 10.0, \n            n_samples_per_epoch=n_samples_per_epoch,\n            gradient_estimation_method=gradient_estimation_mode,\n   )\n    vi.run(data, 250, max_epochs_without_improvement=250)\n    return vi\n</pre> def train_estimator(gradient_estimation_mode, n_samples_per_epoch):     torch.manual_seed(0)     posterior_estimator = setup_flow()      optimizer = torch.optim.Adam(posterior_estimator.parameters(), 1e-3)     loss = L2Loss(sir)     vi = VI(loss = loss,              posterior_estimator=posterior_estimator,              prior=prior,              optimizer=optimizer,             w = 10.0,              n_samples_per_epoch=n_samples_per_epoch,             gradient_estimation_method=gradient_estimation_mode,    )     vi.run(data, 250, max_epochs_without_improvement=250)     return vi In\u00a0[7]: Copied! <pre>%%time\nvi_pathwise = train_estimator(\"pathwise\", 5)\n</pre> %%time vi_pathwise = train_estimator(\"pathwise\", 5) <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 250/250 [05:52&lt;00:00,  1.41s/it, loss=1.47e+3, reg.=99.6, total=1.57e+3, best loss=491, epochs since improv.=55]</pre> <pre>CPU times: user 5min 39s, sys: 2min 26s, total: 8min 5s\nWall time: 5min 52s\n</pre> <pre>\n</pre> In\u00a0[8]: Copied! <pre>%%time\nvi_score = train_estimator(\"score\", 5)\n</pre> %%time vi_score = train_estimator(\"score\", 5) <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 250/250 [03:07&lt;00:00,  1.33it/s, loss=8.17e+4, reg.=187, total=8.19e+4, best loss=4.33e+4, epochs since improv.=111]</pre> <pre>CPU times: user 2min 49s, sys: 2min 23s, total: 5min 13s\nWall time: 3min 7s\n</pre> <pre>\n</pre> In\u00a0[9]: Copied! <pre>f, ax = plt.subplots()\nax.plot(vi_pathwise.losses_hist[\"total\"], label = \"pathwise\")\nax.plot(vi_score.losses_hist[\"total\"], label = \"score function\")\nax.set_yscale(\"log\")\nax.set_ylabel(\"Loss\")\nax.set_xlabel(\"Epoch\")\nax.legend(title=\"Gradient method\")\n</pre> f, ax = plt.subplots() ax.plot(vi_pathwise.losses_hist[\"total\"], label = \"pathwise\") ax.plot(vi_score.losses_hist[\"total\"], label = \"score function\") ax.set_yscale(\"log\") ax.set_ylabel(\"Loss\") ax.set_xlabel(\"Epoch\") ax.legend(title=\"Gradient method\") Out[9]: <pre>&lt;matplotlib.legend.Legend at 0x2ab4e3250&gt;</pre> In\u00a0[10]: Copied! <pre>vi_pathwise.posterior_estimator.load_state_dict(vi_pathwise.best_estimator_state_dict)\nvi_score.posterior_estimator.load_state_dict(vi_score.best_estimator_state_dict)\n</pre> vi_pathwise.posterior_estimator.load_state_dict(vi_pathwise.best_estimator_state_dict) vi_score.posterior_estimator.load_state_dict(vi_score.best_estimator_state_dict) Out[10]: <pre>&lt;All keys matched successfully&gt;</pre> In\u00a0[11]: Copied! <pre>samples_pw = vi_pathwise.posterior_estimator.sample(10000)[0].detach().numpy()\nsamples_score = vi_score.posterior_estimator.sample(10000)[0].detach().numpy()\n\npygtc.plotGTC(chains=[samples_pw, samples_score],\n              figureSize=8, \n              truths = true_parameters.numpy(), \n              chainLabels=[\"pathwise\", \"score function\"], \n              paramNames=[\"inital_fraction\", r\"$\\beta$\", r\"$\\gamma$\"]);\n</pre> samples_pw = vi_pathwise.posterior_estimator.sample(10000)[0].detach().numpy() samples_score = vi_score.posterior_estimator.sample(10000)[0].detach().numpy()  pygtc.plotGTC(chains=[samples_pw, samples_score],               figureSize=8,                truths = true_parameters.numpy(),                chainLabels=[\"pathwise\", \"score function\"],                paramNames=[\"inital_fraction\", r\"$\\beta$\", r\"$\\gamma$\"]); In\u00a0[12]: Copied! <pre># compare the predictions to the synthetic data:\n\nf, ax = plt.subplots(1, 2, figsize=(10,4), sharex=True, sharey=True)\nalpha=0.7\n\nfor i in range(25):\n    with torch.no_grad():\n        sim_sir_pw = sir.run_and_observe(vi_pathwise.posterior_estimator.sample(1)[0][0])\n        ax[0].plot(sim_sir_pw[0].numpy(), color = \"C0\", alpha=alpha)\n        ax[0].plot(sim_sir_pw[1].numpy(), color = \"C1\", alpha=alpha)\n        sim_sir_score = sir.run_and_observe(vi_score.posterior_estimator.sample(1)[0][0])\n        ax[1].plot(sim_sir_score[0].numpy(), color = \"C0\", alpha=alpha)\n        ax[1].plot(sim_sir_score[1].numpy(), color = \"C1\", alpha=alpha)\n    \nax[1].plot([], [], color = \"C0\", label = \"predicted infected\")\nax[1].plot([], [], color = \"C1\", label = \"predicted recovered\")\nfor i in range(2):\n    ax[i].plot(data[0], color = \"black\", linewidth=2, label = \"data infected\")\n    ax[i].plot(data[1], color = \"black\", linewidth=2, label = \"data recovered\", linestyle=\"--\")\n    ax[i].set_xlabel(\"Time-step\")\n\nax[0].set_title(\"Pathwise gradient estimation\")\nax[1].set_title(\"Score function gradient estimation\")\n\nax[1].legend(loc=\"center left\", bbox_to_anchor=(1,0.5))\nplt.subplots_adjust(wspace=0.05, hspace=0.05)\n</pre> # compare the predictions to the synthetic data:  f, ax = plt.subplots(1, 2, figsize=(10,4), sharex=True, sharey=True) alpha=0.7  for i in range(25):     with torch.no_grad():         sim_sir_pw = sir.run_and_observe(vi_pathwise.posterior_estimator.sample(1)[0][0])         ax[0].plot(sim_sir_pw[0].numpy(), color = \"C0\", alpha=alpha)         ax[0].plot(sim_sir_pw[1].numpy(), color = \"C1\", alpha=alpha)         sim_sir_score = sir.run_and_observe(vi_score.posterior_estimator.sample(1)[0][0])         ax[1].plot(sim_sir_score[0].numpy(), color = \"C0\", alpha=alpha)         ax[1].plot(sim_sir_score[1].numpy(), color = \"C1\", alpha=alpha)      ax[1].plot([], [], color = \"C0\", label = \"predicted infected\") ax[1].plot([], [], color = \"C1\", label = \"predicted recovered\") for i in range(2):     ax[i].plot(data[0], color = \"black\", linewidth=2, label = \"data infected\")     ax[i].plot(data[1], color = \"black\", linewidth=2, label = \"data recovered\", linestyle=\"--\")     ax[i].set_xlabel(\"Time-step\")  ax[0].set_title(\"Pathwise gradient estimation\") ax[1].set_title(\"Score function gradient estimation\")  ax[1].legend(loc=\"center left\", bbox_to_anchor=(1,0.5)) plt.subplots_adjust(wspace=0.05, hspace=0.05) In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"examples/variational_inference/04-score_vs_pathwise_gradient/#score-vs-pathwise-gradient","title":"Score vs Pathwise Gradient\u00b6","text":""},{"location":"examples/variational_inference/05-gpu_parallelisation/","title":"05 gpu parallelisation","text":"In\u00a0[\u00a0]: Copied! <pre>\"\"\"\nThis scripts shows how to run blackbirds in parallel using MPI4PY.\nThe parallelization is done across the number of parameters that are sampled\nin each epoch from the posterior candidate.\n\nAs an example we consider the SIR model.\n\"\"\"\nimport argparse\nimport torch\nimport networkx\nimport normflows as nf\nimport numpy as np\n</pre> \"\"\" This scripts shows how to run blackbirds in parallel using MPI4PY. The parallelization is done across the number of parameters that are sampled in each epoch from the posterior candidate.  As an example we consider the SIR model. \"\"\" import argparse import torch import networkx import normflows as nf import numpy as np In\u00a0[\u00a0]: Copied! <pre>from blackbirds.models.sir import SIR\nfrom blackbirds.infer.vi import VI\nfrom blackbirds.mpi_setup import mpi_rank\nfrom blackbirds.simulate import simulate_and_observe_model\n</pre> from blackbirds.models.sir import SIR from blackbirds.infer.vi import VI from blackbirds.mpi_setup import mpi_rank from blackbirds.simulate import simulate_and_observe_model In\u00a0[\u00a0]: Copied! <pre>class L2Loss:\n    def __init__(self, model):\n        self.model = model\n        self.loss_fn = torch.nn.MSELoss()\n\n    def __call__(self, params, data):\n        observed_outputs = simulate_and_observe_model(\n            self.model, params, gradient_horizon=0\n        )\n        return self.loss_fn(observed_outputs[0], data[0])\n</pre> class L2Loss:     def __init__(self, model):         self.model = model         self.loss_fn = torch.nn.MSELoss()      def __call__(self, params, data):         observed_outputs = simulate_and_observe_model(             self.model, params, gradient_horizon=0         )         return self.loss_fn(observed_outputs[0], data[0]) In\u00a0[\u00a0]: Copied! <pre>def make_model(n_agents, n_timesteps, device):\n    graph = networkx.watts_strogatz_graph(n_agents, 10, 0.1)\n    return SIR(graph=graph, n_timesteps=n_timesteps, device=device)\n</pre> def make_model(n_agents, n_timesteps, device):     graph = networkx.watts_strogatz_graph(n_agents, 10, 0.1)     return SIR(graph=graph, n_timesteps=n_timesteps, device=device) In\u00a0[\u00a0]: Copied! <pre>def make_flow(device):\n    # Define flows\n    torch.manual_seed(0)\n    K = 4\n    latent_size = 3\n    hidden_units = 64\n    hidden_layers = 2\n\n    flows = []\n    for _ in range(K):\n        flows += [\n            nf.flows.AutoregressiveRationalQuadraticSpline(\n                latent_size, hidden_layers, hidden_units\n            )\n        ]\n        flows += [nf.flows.LULinearPermute(latent_size)]\n\n    # Set prior and q0\n    q0 = nf.distributions.DiagGaussian(3, trainable=False)\n\n    # Construct flow model\n    flow = nf.NormalizingFlow(q0=q0, flows=flows)\n    return flow.to(device)\n</pre> def make_flow(device):     # Define flows     torch.manual_seed(0)     K = 4     latent_size = 3     hidden_units = 64     hidden_layers = 2      flows = []     for _ in range(K):         flows += [             nf.flows.AutoregressiveRationalQuadraticSpline(                 latent_size, hidden_layers, hidden_units             )         ]         flows += [nf.flows.LULinearPermute(latent_size)]      # Set prior and q0     q0 = nf.distributions.DiagGaussian(3, trainable=False)      # Construct flow model     flow = nf.NormalizingFlow(q0=q0, flows=flows)     return flow.to(device) In\u00a0[\u00a0]: Copied! <pre>def train_flow(flow, model, true_data, n_epochs, n_samples_per_epoch, device):\n    torch.manual_seed(0)\n    # Define a prior\n    prior = torch.distributions.MultivariateNormal(\n        -2.0 * torch.ones(3, device=device), torch.eye(3, device=device)\n    )\n\n    optimizer = torch.optim.AdamW(flow.parameters(), lr=1e-3)\n\n    # We set the regularisation weight to 10.\n    w = 100\n\n    loss = L2Loss(model)\n    # Note that we can track the progress of the training by using tensorboard.\n    # tensorboard --logdir=runs\n    vi = VI(\n        loss=loss,\n        posterior_estimator=flow,\n        prior=prior,\n        optimizer=optimizer,\n        w=w,\n        n_samples_per_epoch=n_samples_per_epoch,\n        device=device,\n    )\n\n    # and we run for 500 epochs without early stopping.\n    vi.run(true_data, n_epochs=n_epochs, max_epochs_without_improvement=np.inf)\n</pre> def train_flow(flow, model, true_data, n_epochs, n_samples_per_epoch, device):     torch.manual_seed(0)     # Define a prior     prior = torch.distributions.MultivariateNormal(         -2.0 * torch.ones(3, device=device), torch.eye(3, device=device)     )      optimizer = torch.optim.AdamW(flow.parameters(), lr=1e-3)      # We set the regularisation weight to 10.     w = 100      loss = L2Loss(model)     # Note that we can track the progress of the training by using tensorboard.     # tensorboard --logdir=runs     vi = VI(         loss=loss,         posterior_estimator=flow,         prior=prior,         optimizer=optimizer,         w=w,         n_samples_per_epoch=n_samples_per_epoch,         device=device,     )      # and we run for 500 epochs without early stopping.     vi.run(true_data, n_epochs=n_epochs, max_epochs_without_improvement=np.inf) In\u00a0[\u00a0]: Copied! <pre>if __name__ == \"__main__\":\n    # parse arguments from cli\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--n_epochs\", type=int, default=500)\n    parser.add_argument(\"--n_agents\", type=int, default=5000)\n    parser.add_argument(\"--n_timesteps\", type=int, default=100)\n    parser.add_argument(\"--n_samples_per_epoch\", type=int, default=5)\n    parser.add_argument(\"--device_ids\", default=[\"cpu\"], nargs=\"+\")\n    args = parser.parse_args()\n\n    # device of this rank\n    device = args.device_ids[mpi_rank]\n\n    model = make_model(args.n_agents, args.n_timesteps, device)\n    true_parameters = torch.tensor(\n        [0.05, 0.05, 0.05], device=device\n    ).log10()  # SIR takes log parameters\n    true_data = model.run_and_observe(true_parameters)\n    flow = make_flow(device)\n    train_flow(\n        flow, model, true_data, args.n_epochs, args.n_samples_per_epoch, device=device\n    )\n</pre> if __name__ == \"__main__\":     # parse arguments from cli     parser = argparse.ArgumentParser()     parser.add_argument(\"--n_epochs\", type=int, default=500)     parser.add_argument(\"--n_agents\", type=int, default=5000)     parser.add_argument(\"--n_timesteps\", type=int, default=100)     parser.add_argument(\"--n_samples_per_epoch\", type=int, default=5)     parser.add_argument(\"--device_ids\", default=[\"cpu\"], nargs=\"+\")     args = parser.parse_args()      # device of this rank     device = args.device_ids[mpi_rank]      model = make_model(args.n_agents, args.n_timesteps, device)     true_parameters = torch.tensor(         [0.05, 0.05, 0.05], device=device     ).log10()  # SIR takes log parameters     true_data = model.run_and_observe(true_parameters)     flow = make_flow(device)     train_flow(         flow, model, true_data, args.n_epochs, args.n_samples_per_epoch, device=device     )"},{"location":"examples/variational_inference/06-classical_posterior/","title":"Variational Inference with classical posterior","text":"<p>In this notebook we set the VI loss to be the negative log-likelihood, to recover the classical posterior.</p> In\u00a0[2]: Copied! <pre>from blackbirds.models.random_walk import RandomWalk\nfrom blackbirds.infer.vi import VI\nfrom blackbirds.posterior_estimators import TrainableGaussian\nfrom blackbirds.simulate import simulate_and_observe_model\n\nimport torch\nimport math\nimport matplotlib.pyplot as plt\nimport pandas as pd\n</pre> from blackbirds.models.random_walk import RandomWalk from blackbirds.infer.vi import VI from blackbirds.posterior_estimators import TrainableGaussian from blackbirds.simulate import simulate_and_observe_model  import torch import math import matplotlib.pyplot as plt import pandas as pd In\u00a0[9]: Copied! <pre>rw = RandomWalk(n_timesteps=40)\n</pre> rw = RandomWalk(n_timesteps=40) In\u00a0[10]: Copied! <pre>true_p = torch.logit(torch.tensor(0.25))\ndata = rw.run_and_observe(torch.tensor([true_p]))\n\nplt.plot(data[0].numpy())\n</pre> true_p = torch.logit(torch.tensor(0.25)) data = rw.run_and_observe(torch.tensor([true_p]))  plt.plot(data[0].numpy()) Out[10]: <pre>[&lt;matplotlib.lines.Line2D at 0x14eb08a00&gt;]</pre> In\u00a0[24]: Copied! <pre>class LogLikelihoodLoss:\n    def __init__(self, model):\n        self.model = model\n        \n    def __call__(self, params, data):\n        N = self.model.n_timesteps\n        p = torch.sigmoid(params[0])\n        lp = 0\n        for n in range(1, N+1):\n            if data[0][n] == data[0][n-1] + 1:\n                lp += p.log()\n            else:\n                lp += (1 - p).log()\n            #k = int(data[0][n].item())\n            #likelihood = math.comb(n, (n+k)//2) * p**((n+k)//2) * (1-p)**((n-k)//2)\n            #lp += likelihood.log()\n        return -lp\n</pre> class LogLikelihoodLoss:     def __init__(self, model):         self.model = model              def __call__(self, params, data):         N = self.model.n_timesteps         p = torch.sigmoid(params[0])         lp = 0         for n in range(1, N+1):             if data[0][n] == data[0][n-1] + 1:                 lp += p.log()             else:                 lp += (1 - p).log()             #k = int(data[0][n].item())             #likelihood = math.comb(n, (n+k)//2) * p**((n+k)//2) * (1-p)**((n-k)//2)             #lp += likelihood.log()         return -lp In\u00a0[48]: Copied! <pre>posterior_estimator = TrainableGaussian([0.], 1.0)\nprior = torch.distributions.Normal(true_p + 0.1, 0.1)\noptimizer = torch.optim.Adam(posterior_estimator.parameters(), 1e-2)\nll = LogLikelihoodLoss(rw)\n\nvi = VI(ll, posterior_estimator=posterior_estimator, prior=prior, optimizer=optimizer, w = 1.0, n_samples_regularisation=1000)\n</pre> posterior_estimator = TrainableGaussian([0.], 1.0) prior = torch.distributions.Normal(true_p + 0.1, 0.1) optimizer = torch.optim.Adam(posterior_estimator.parameters(), 1e-2) ll = LogLikelihoodLoss(rw)  vi = VI(ll, posterior_estimator=posterior_estimator, prior=prior, optimizer=optimizer, w = 1.0, n_samples_regularisation=1000) In\u00a0[49]: Copied! <pre># we can now train the estimator for a 100 epochs\nvi.run(data, 1000, max_epochs_without_improvement=100)\n</pre> # we can now train the estimator for a 100 epochs vi.run(data, 1000, max_epochs_without_improvement=100) <pre> 28%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                                                                                                                                              | 284/1000 [00:05&lt;00:13, 51.15it/s, loss=23.5, reg.=0.692, total=24.2, best loss=23.5, epochs since improv.=100]\n</pre> In\u00a0[50]: Copied! <pre>df = pd.DataFrame(vi.losses_hist)\ndf.plot()\n</pre> df = pd.DataFrame(vi.losses_hist) df.plot() Out[50]: <pre>&lt;Axes: &gt;</pre> In\u00a0[51]: Copied! <pre># We can now load the best model\nposterior_estimator.load_state_dict(vi.best_estimator_state_dict)\n</pre> # We can now load the best model posterior_estimator.load_state_dict(vi.best_estimator_state_dict) Out[51]: <pre>&lt;All keys matched successfully&gt;</pre> In\u00a0[52]: Copied! <pre>data_diff = data[0].diff()\np_hat = 0.5 * (1 + 1 / (len(data[0])-1) * data_diff.sum())\np_hat\n</pre> data_diff = data[0].diff() p_hat = 0.5 * (1 + 1 / (len(data[0])-1) * data_diff.sum()) p_hat                 Out[52]: <pre>tensor(0.5000)</pre> In\u00a0[53]: Copied! <pre># and plot the posterior\nwith torch.no_grad():\n    samples = posterior_estimator.sample(20000)[0].flatten().cpu()\nplt.hist(torch.sigmoid(samples), density=True, bins=100);\nplt.axvline(torch.sigmoid(true_p), label = \"true value\", color = \"black\", linestyle=\":\")\n</pre> # and plot the posterior with torch.no_grad():     samples = posterior_estimator.sample(20000)[0].flatten().cpu() plt.hist(torch.sigmoid(samples), density=True, bins=100); plt.axvline(torch.sigmoid(true_p), label = \"true value\", color = \"black\", linestyle=\":\") Out[53]: <pre>&lt;matplotlib.lines.Line2D at 0x14fafa3e0&gt;</pre> In\u00a0[54]: Copied! <pre># compare the predictions to the synthetic data:\n\nf, ax = plt.subplots()\n\nfor i in range(50):\n    with torch.no_grad():\n        sim_rw = rw.run_and_observe(posterior_estimator.sample(1)[0])[0].numpy()\n    ax.plot(sim_rw, color = \"C0\", alpha=0.5)\n    \nax.plot([], [], color = \"C0\", label = \"predicted\")\nax.plot(data[0], color = \"black\", linewidth=2, label = \"data\")\n\nax.legend()\n</pre> # compare the predictions to the synthetic data:  f, ax = plt.subplots()  for i in range(50):     with torch.no_grad():         sim_rw = rw.run_and_observe(posterior_estimator.sample(1)[0])[0].numpy()     ax.plot(sim_rw, color = \"C0\", alpha=0.5)      ax.plot([], [], color = \"C0\", label = \"predicted\") ax.plot(data[0], color = \"black\", linewidth=2, label = \"data\")  ax.legend() Out[54]: <pre>&lt;matplotlib.legend.Legend at 0x14ecafbe0&gt;</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"examples/variational_inference/06-classical_posterior/#variational-inference-with-classical-posterior","title":"Variational Inference with classical posterior\u00b6","text":""}]}